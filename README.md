# DevOps---JFKZ
  
# 1) PrÃ©sentation gÃ©nÃ©rale  
Dans le cadre de lâ€™unitÃ© dâ€™enseignement DevOps du **Master 2 RÃ©seaux et TÃ©lÃ©communications**, ce projet a pour objectif de mettre en Å“uvre une infrastructure complÃ¨te intÃ©grant les notions fondamentales de **conteneurisation**, **orchestration** et **automatisation de la configuration**. Ces concepts constituent aujourdâ€™hui des piliers incontournables des architectures modernes utilisÃ©es en entreprise, notamment dans les environnements de production Ã  forte exigence de disponibilitÃ©, de scalabilitÃ© et de sÃ©curitÃ©.

Lâ€™Ã©volution des systÃ¨mes dâ€™information vers des architectures distribuÃ©es, dynamiques et fortement automatisÃ©es a profondÃ©ment modifiÃ© les pratiques dâ€™exploitation. Les approches traditionnelles, basÃ©es sur des configurations manuelles et spÃ©cifiques Ã  chaque serveur, montrent rapidement leurs limites face Ã  la complexitÃ© croissante des infrastructures. Dans ce contexte, les dÃ©marches **DevOps** visent Ã  rapprocher les Ã©quipes de dÃ©veloppement et dâ€™exploitation autour de processus automatisÃ©s, reproductibles et contrÃ´lÃ©s, rÃ©duisant les erreurs humaines et accÃ©lÃ©rant les cycles de mise en production.

Lâ€™objectif principal de ce projet est donc de **concevoir et dÃ©ployer une infrastructure systÃ¨me rÃ©aliste**, inspirÃ©e des bonnes pratiques observÃ©es en milieu professionnel. Cette infrastructure doit permettre :
- le provisionnement automatique des ressources systÃ¨mes,
- la configuration homogÃ¨ne des machines,
- le dÃ©ploiement applicatif conteneurisÃ©,
- et la montÃ©e en charge dynamique des services en fonction de la demande.

Pour rÃ©pondre Ã  ces enjeux, le projet sâ€™appuie sur une chaÃ®ne dâ€™outils reprÃ©sentative des stacks DevOps modernes. Terraform (ou OpenTofu) est utilisÃ© pour le provisionnement de lâ€™infrastructure virtuelle, Ansible pour lâ€™automatisation de la configuration des systÃ¨mes, Podman pour la conteneurisation, et Kubernetes pour lâ€™orchestration et la gestion du cycle de vie applicatif. Cette combinaison permet de couvrir lâ€™ensemble du cycle, depuis la crÃ©ation des machines virtuelles jusquâ€™Ã  lâ€™exploitation dâ€™une application scalable en production.

Au-delÃ  de la simple mise en Å“uvre technique, ce projet vise Ã©galement Ã  **comprendre les principes sous-jacents** Ã  ces outils : pourquoi ils sont utilisÃ©s, quels problÃ¨mes ils rÃ©solvent, et comment ils sâ€™articulent entre eux. Lâ€™approche retenue privilÃ©gie une infrastructure dÃ©clarative, reproductible et documentÃ©e, capable dâ€™Ãªtre redÃ©ployÃ©e intÃ©gralement sans intervention manuelle, conformÃ©ment aux exigences actuelles des environnements professionnels.

![Maquette](https://github.com/egoMasa/DevOps-JFKZ/blob/main/images/Maquette.png)

# 2) Cahier des charges  
  Le cahier des charges du projet dÃ©finit les briques techniques nÃ©cessaires Ã  la construction de lâ€™infrastructure cible. Chaque composant a Ã©tÃ© choisi afin de rÃ©pondre Ã  un besoin prÃ©cis tout en respectant une logique de cohÃ©rence globale et dâ€™alignement avec les pratiques industrielles.

| Domaine                            | Outil / Technologie   | RÃ´le dans le projet                                              |
| ---------------------------------- | --------------------- | ---------------------------------------------------------------- |
| Hyperviseur                        | Proxmox               | HÃ©bergement des machines virtuelles constituant lâ€™infrastructure |
| Infrastructure as Code             | Terraform / OpenTofu  | Provisionnement automatisÃ© des ressources (VM, rÃ©seau, stockage) |
| Moteur de conteneurisation         | Podman                | ExÃ©cution sÃ©curisÃ©e des conteneurs applicatifs                   |
| Automatisation de la configuration | Ansible               | Configuration et orchestration des machines et services          |
| Orchestration de conteneurs        | Kubernetes            | DÃ©ploiement, exposition et montÃ©e en charge des applications     |
| Service applicatif                 | Wiki.js (prioritaire) | Application mÃ©tier dÃ©ployÃ©e sur le cluster                       |

Initialement, plusieurs services applicatifs ont Ã©tÃ© envisagÃ©s (Nextcloud, GLPI). Toutefois, au cours du projet, **Wiki.js** a Ã©tÃ© retenu comme application principale. Ce choix sâ€™explique par plusieurs facteurs :
- une architecture reprÃ©sentative dâ€™une application web moderne,
- une dÃ©pendance Ã  une base de donnÃ©es externe,
- une documentation officielle orientÃ©e Kubernetes,
- et des contraintes rÃ©elles en matiÃ¨re de dÃ©ploiement, dâ€™initialisation et de scalabilitÃ©.

Wiki.js constitue ainsi un cas dâ€™Ã©tude pertinent pour illustrer les problÃ©matiques de dÃ©ploiement applicatif sur un cluster Kubernetes, notamment en ce qui concerne la phase dâ€™initialisation contrÃ´lÃ©e, lâ€™exposition via Ingress et la montÃ©e en charge automatisÃ©e.

# Structure du projet
```
.
â”œâ”€â”€ ansible
â”‚Â Â  â”œâ”€â”€ 1-deploy-k8s-master.yaml
â”‚Â Â  â”œâ”€â”€ 2-deploy-k8s-workers.yaml
â”‚Â Â  â”œâ”€â”€ 3-deploy-db-postgres.yaml
â”‚Â Â  â”œâ”€â”€ 4-deploy-metallb.yaml
â”‚Â Â  â”œâ”€â”€ 5-deploy-ingress-nginx.yaml
â”‚Â Â  â”œâ”€â”€ 6-deploy-metrics-server.yaml
â”‚Â Â  â”œâ”€â”€ 7-deploy-wikijs-init.yaml
â”‚Â Â  â”œâ”€â”€ 8-deploy-wikijs-scale.yaml
â”‚Â Â  â”œâ”€â”€ artifacts
â”‚Â Â  â”‚Â Â  â””â”€â”€ join-workers.sh
â”‚Â Â  â”œâ”€â”€ cis_ubuntu24_audit.yml
â”‚Â Â  â”œâ”€â”€ inventory.ini
â”‚Â Â  â”œâ”€â”€ inventory.template.ini
â”‚Â Â  â”œâ”€â”€ reports
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ tf-k8s-master
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ cis_audit_result_03_01_2026_18h08.txt
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ tf-k8s-node-1
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ cis_audit_result_03_01_2026_18h08.txt
â”‚Â Â  â”‚Â Â  â””â”€â”€ tf-k8s-node-2
â”‚Â Â  â”‚Â Â      â””â”€â”€ cis_audit_result_03_01_2026_18h08.txt
â”‚Â Â  â”œâ”€â”€ roles
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ ubuntu24_cis
â”‚Â Â  â”‚Â Â  â””â”€â”€ ubuntu24_cis_audit
â”‚Â Â  â”œâ”€â”€ terraform.tfstate
â”‚Â Â  â””â”€â”€ ubuntu24_hardening_nv1.yml
â”œâ”€â”€ k8s
â”‚Â Â  â”œâ”€â”€ 00-metallb
â”‚Â Â  â”‚Â Â  â””â”€â”€ metallb-config.yaml
â”‚Â Â  â”œâ”€â”€ 01-ingress-nginx
â”‚Â Â  â”‚Â Â  â””â”€â”€ kustomization.yaml
â”‚Â Â  â””â”€â”€ 02-wikijs
â”‚Â Â      â””â”€â”€ values-wikijs.yaml
â”œâ”€â”€ Maquette.drawio
â”œâ”€â”€ README.md
â””â”€â”€ terraform
    â”œâ”€â”€ inventory.tftpl
    â”œâ”€â”€ main.tf
    â”œâ”€â”€ outputs.tf
    â”œâ”€â”€ terraform.tfstate
    â”œâ”€â”€ terraform.tfvars
    â”œâ”€â”€ variables.tf
    â””â”€â”€ versions.tf
```

--- 

# Worflow finale Ã  suivre pour dÃ©ployer le lab
```
cd /devops/terraform/
rm -rf .terraform
rm -f .terraform.lock.hcl
rm -f terraform.tfstate terraform.tfstate.backup
rm -rf .terraform .terraform.lock.hcl
terraform init
terraform plan
terraform apply

---

ssh-keygen -f '/home/jeremy/.ssh/known_hosts' -R '192.168.122.150'
ssh-keygen -f '/home/jeremy/.ssh/known_hosts' -R '192.168.122.151'
ssh-keygen -f '/home/jeremy/.ssh/known_hosts' -R '192.168.122.152'
ssh-keygen -f '/home/jeremy/.ssh/known_hosts' -R '192.168.122.153'

---

cd /devops/ansible/
ansible-playbook -i inventory.ini 1-deploy-k8s-master.yaml
ansible-playbook -i inventory.ini 2-deploy-k8s-workers.yaml
ansible-playbook -i inventory.ini 3-deploy-db-postgres.yaml
ansible-playbook -i inventory.ini 4-deploy-metallb.yaml
ansible-playbook -i inventory.ini 5-deploy-ingress-nginx.yaml
ansible-playbook -i inventory.ini 6-deploy-metrics-server.yaml
ansible-playbook -i inventory.ini 7-deploy-wikijs-init.yaml

- EMAIL : test@gmail.com
- Password : azerty123
- URL : http://wikijs.lab
  
ansible-playbook -i inventory.ini 8-deploy-wikijs-scale.yaml

--- VÃ©rifications 
ssh ansible@192.168.122.150
kubectl get nodes,pods,svc,ingress,ep,pvc,hpa -A
```

# Partie 1 : Hyperviseur Proxmox
## 1.1) Notion d'hyperviseur
Dans toute architecture informatique moderne, la virtualisation constitue un **socle technique fondamental**. Elle permet de dÃ©coupler les ressources matÃ©rielles physiques (CPU, mÃ©moire, stockage, rÃ©seau) des systÃ¨mes dâ€™exploitation et des services qui les exploitent. Cette abstraction est rendue possible grÃ¢ce Ã  un composant clÃ© : **lâ€™hyperviseur**.

Un hyperviseur est une couche logicielle chargÃ©e de crÃ©er, exÃ©cuter et isoler plusieurs **machines virtuelles (VM)** sur un mÃªme serveur physique. Chaque machine virtuelle dispose de son propre systÃ¨me dâ€™exploitation, de ses ressources allouÃ©es et de son environnement dâ€™exÃ©cution, tout en partageant le matÃ©riel sous-jacent avec dâ€™autres VM.

Cette approche prÃ©sente plusieurs avantages majeurs dans un contexte professionnel :
- **Optimisation des ressources matÃ©rielles**, en Ã©vitant la sous-utilisation des serveurs physiques,
- **Isolation forte** entre les environnements (sÃ©curitÃ©, stabilitÃ©),
- **FlexibilitÃ© opÃ©rationnelle**, avec la possibilitÃ© de crÃ©er, dÃ©truire ou migrer des VM dynamiquement,
- **ReproductibilitÃ©**, essentielle dans les dÃ©marches DevOps et Infrastructure as Code.
    
### **Hyperviseurs de type 1 et type 2**

On distingue classiquement deux grandes familles dâ€™hyperviseurs, selon leur mode dâ€™intÃ©gration au systÃ¨me hÃ´te.

Les **hyperviseurs de type 2**, dits _hosted_, sâ€™exÃ©cutent au-dessus dâ€™un systÃ¨me dâ€™exploitation classique (Windows, Linux, macOS). Ils sont gÃ©nÃ©ralement utilisÃ©s dans des contextes de dÃ©veloppement ou de test. Des solutions comme VirtualBox ou VMware Workstation en sont des exemples. Bien que simples Ã  mettre en Å“uvre, ces hyperviseurs introduisent une couche supplÃ©mentaire qui dÃ©grade les performances et limite les usages en production.

Ã€ lâ€™inverse, les **hyperviseurs de type 1**, dits _bare-metal_, sâ€™exÃ©cutent directement sur le matÃ©riel physique, sans systÃ¨me dâ€™exploitation intermÃ©diaire. Lâ€™hyperviseur devient lui-mÃªme le systÃ¨me central de la machine. Cette architecture permet :
- de rÃ©duire la latence et les surcoÃ»ts liÃ©s Ã  la virtualisation,
- dâ€™amÃ©liorer les performances globales,
- dâ€™offrir un niveau dâ€™isolation et de fiabilitÃ© adaptÃ© aux environnements de production.

Dans les infrastructures professionnelles (datacenters, clouds privÃ©s, plateformes dâ€™hÃ©bergement), **les hyperviseurs de type 1 sont la norme**.

### **Pourquoi Proxmox dans ce projet**

Dans le cadre de ce laboratoire, le choix sâ€™est portÃ© sur **Proxmox VE**, un hyperviseur de type 1 open source, basÃ© sur le noyau Linux et sâ€™appuyant sur les technologies KVM (virtualisation matÃ©rielle) et LXC (conteneurs systÃ¨me).

Plusieurs raisons motivent ce choix.

Tout dâ€™abord, Proxmox offre une **approche open source et souveraine** de la virtualisation. Contrairement Ã  certaines solutions propriÃ©taires, il permet de mettre en place une infrastructure complÃ¨te sans dÃ©pendance Ã  un modÃ¨le de licence contraignant. Ce point est particuliÃ¨rement pertinent dans un contexte acadÃ©mique et professionnel, oÃ¹ les coÃ»ts et les Ã©volutions de licences peuvent devenir un facteur bloquant.

Ensuite, Proxmox propose une **intÃ©gration native des briques essentielles** dâ€™une plateforme de virtualisation moderne :
- gestion avancÃ©e des machines virtuelles,
- gestion du stockage (local, rÃ©seau, volumes),
- administration rÃ©seau (bridges, VLAN),
- snapshots, sauvegardes et migrations Ã  chaud.

Enfin, le choix de Proxmox sâ€™inscrit dans une logique de **rÃ©alisme industriel**. Les Ã©volutions rÃ©centes des modÃ¨les Ã©conomiques de certains acteurs historiques de la virtualisation, notamment VMware, ont mis en lumiÃ¨re les limites des solutions propriÃ©taires Ã  long terme. De nombreuses organisations se tournent aujourdâ€™hui vers des alternatives open source afin de reprendre le contrÃ´le de leur infrastructure et de rÃ©duire les coÃ»ts opÃ©rationnels.

### **RÃ´le de lâ€™hyperviseur dans lâ€™architecture du projet**

Dans ce projet, Proxmox constitue la **couche fondationnelle** de lâ€™infrastructure. Il hÃ©berge lâ€™ensemble des machines virtuelles nÃ©cessaires au laboratoire :
- le nÅ“ud maÃ®tre Kubernetes,
- les nÅ“uds workers Kubernetes,
- la machine dÃ©diÃ©e Ã  la base de donnÃ©es PostgreSQL.

Lâ€™hyperviseur nâ€™intervient pas dans lâ€™orchestration applicative ni dans la gestion des conteneurs, mais il fournit un environnement stable, isolÃ© et reproductible sur lequel sâ€™appuient les couches supÃ©rieures (Ansible, Kubernetes, Helm).

Cette sÃ©paration claire des responsabilitÃ©s reflÃ¨te une architecture conforme aux bonnes pratiques :
- **Proxmox** : gestion des ressources physiques et des VM,
- **Ansible** : automatisation de la configuration des systÃ¨mes,
- **Kubernetes** : orchestration des conteneurs et des services applicatifs.    

Ainsi, lâ€™hyperviseur joue un rÃ´le dÃ©terminant dans la cohÃ©rence globale du projet, en garantissant une base robuste, performante et alignÃ©e avec les pratiques professionnelles actuelles.
## 1.2) Installation de proxmox
Afin de mettre en place un hyperviseur, nous utilisons un PC basÃ© sur Linux Mint sur lequel nous allons utilisÃ© QEMU+KVM (capot) via Virt Manager (interface) pour dÃ©ployer une VM Hyperviseur dans lequel sera hÃ©bergÃ© tout le lab. 

Lien Proxmox VE 9.1 ISO : https://www.proxmox.com/en/downloads/proxmox-virtual-environment/iso
1. Installation de QEMU KVM et virt manager
```bash
sudo apt update && sudo apt upgrade -y
sudo apt install qemu-system virt-manager
```
2. Lancer `Gestionnaire de machines virtuelles`
3. Fichier > CrÃ©er une nouvelle machine virtuelle > MÃ©dia d'installation local (ISO) 
	1. MÃ©dia d'installation : proxmox.iso
	2. SystÃ¨me d'exploitation installer : Debian 13
	3. MÃ©moire : 8128
	4. CPU : 6
	5. Image disque : 150 GiB
	6. Nom : Proxmox
	7. RÃ©seau : NAT 
4. Suivre l'installation jusqu'au reboot de la VM
5. Se rendre sur l'interface web de proxmox : https://IP:8006

Option	Value
Filesystem:	ext4
Disk(s):	/dev/vda
Country:	France
Timezone:	Europe/Paris
Keymap:	fr
Email:	jeremyfournier203@gmail.com
Management Interface:	nic0
Hostname:	proxmox
IP CIDR:	192.168.122.108/24
Gateway:	192.168.122.1
DNS:	192.168.122.1

Maintenant nous avons installÃ© proprement Proxmox sur un VM dÃ©diÃ© et nous allons par la suite configurÃ© proprement, ajouter des composants manquants et mettre en place le lab.

## 1.3) Configuration du routage et des accÃ¨s SSH
* Sur promox activer le routage pour permettre au poste d'administration d'accÃ©der au VMs
```bash
echo "net.ipv4.ip_forward=1" > /etc/sysctl.conf
sysctl -p
```
* Sur le poste configure une route statique vers le rÃ©seau proxmox
```bash
sudo nmcli con modify "virbr0" +ipv4.routes "192.168.122.0/24 192.168.122.108"
sudo nmcli con down "virbr0"
sudo nmcli con up "virbr0"
```
## 1.4) CrÃ©ation d'une VM template dupliquable (golden)

### 1.4.1) Choix de l'OS golden image
La prochaine Ã©tape consiste Ã  sÃ©lectionner l'OS qui servira de socle Ã  nos machines virtuelles. Pour un cluster Kubernetes, l'OS hÃ´te doit rÃ©pondre Ã  trois exigences critiques : la gestion des **cgroups** (via systemd), la compatibilitÃ© avec la **glibc** (bibliothÃ¨que C standard) et un support mature de **Cloud-Init** pour l'automatisation via Terraform.

Pour effectuer ce choix, plusieurs Ã©coles s'affrontent :
- **L'ultra-lÃ©gÃ¨retÃ© (Alpine Linux) :** Alpine est la rÃ©fÃ©rence pour les images de conteneurs grÃ¢ce Ã  sa taille dÃ©risoire (5-10 Mo). Cependant, son utilisation comme **OS hÃ´te** pour Kubernetes est risquÃ©e. Son architecture basÃ©e sur `musl libc` (au lieu de `glibc`) et l'absence de `systemd` posent des problÃ¨mes de compatibilitÃ© majeurs avec les binaires officiels de `kubelet` et certains plugins rÃ©seau (CNI). Le gain de lÃ©gÃ¨retÃ© ne justifie pas la complexitÃ© de maintenance engendrÃ©e.
- **L'ultra-compatibilitÃ© (Ubuntu Server ISO) :** C'est le choix de la sÃ©curitÃ©. Ubuntu bÃ©nÃ©ficie du support le plus vaste de la communautÃ© Kubernetes. Toutefois, l'installation via une image ISO classique est inadaptÃ©e Ã  notre workflow automatisÃ© : elle est lourde, inclut des services inutiles (snaps, outils de diagnostic) et le processus d'installation manuel est chronophage.
- **L'approche "Cloud-Native" (Images Cloud / Minimal) :** Des distributions comme Debian, Rocky Linux ou Ubuntu Cloud-Image proposent des versions "nues", prÃ©-configurÃ©es pour Ãªtre dÃ©ployÃ©es de faÃ§on Ã©phÃ©mÃ¨re et automatisÃ©e.

|CaractÃ©ristiques|Alpine Linux|Debian 12 (Cloud)|Ubuntu 24.04 (Minimal Cloud)|Rocky Linux 9|
|---|---|---|---|---|
|**Poids (Image)**|~10 Mo|~300 Mo|~350 Mo|~600 Mo|
|**Init System**|OpenRC|Systemd|Systemd|Systemd|
|**BibliothÃ¨que C**|musl libc|glibc|glibc|glibc|
|**Support K8s**|Faible (ExpÃ©rimental)|Excellent|**Natif / Standard**|TrÃ¨s bon (Enterprise)|
|**Cloud-Init**|Partiel|Natif|**Natif (OptimisÃ©)**|Natif|
|**Vitesse Boot**|InstantanÃ©e|Rapide|Rapide|ModÃ©rÃ©e|
Nous avons dÃ©libÃ©rÃ©ment choisi l'utilisation d'une **Cloud Image officielle (.img)**. Ce choix repose sur deux piliers fondamentaux de la philosophie DevOps :
- **Valorisation de l'Infrastructure as Code (IaC) :** En partant d'une image vierge, nous dÃ©plaÃ§ons toute l'intelligence de la configuration vers nos **playbooks Ansible**. Si nous utilisions une image prÃ©-configurÃ©e (oÃ¹ Podman ou K8s seraient dÃ©jÃ  installÃ©s), la valeur ajoutÃ©e de l'automatisation serait masquÃ©e. Ici, le code Ansible devient la seule "source de vÃ©ritÃ©", capable de transformer n'importe quelle instance nue en un nÅ“ud de production sÃ©curisÃ©.
- **Lutte contre le "Configuration Drift" :** Les images personnalisÃ©es manuellement ont tendance Ã  devenir des "boÃ®tes noires" dont on perd la trace des modifications. L'utilisation d'une image Cloud standard garantit une **reproductibilitÃ© totale** : pour mettre Ã  jour le systÃ¨me ou modifier un paramÃ¨tre de sÃ©curitÃ©, il suffit de mettre Ã  jour le playbook Ansible et de redÃ©ployer, assurant ainsi une infrastructure saine et immuable.

Notre choix s'est portÃ© sur **Ubuntu 24.04 LTS (Noble Numbat) en version "Minimal Cloud Image"**. Câ€™est le compromis parfait entre lÃ©gÃ¨retÃ© logicielle (suppression des paquets inutiles), stabilitÃ© du noyau Linux pour Kubernetes et interopÃ©rabilitÃ© native avec les modules Cloud-Init de Proxmox.

* ***Fichier retenu :** `ubuntu-24.04-minimal-cloudimg-amd64.img`
* Lien : https://cloud-images.ubuntu.com/minimal/releases/noble/release/

### 1.4.2) Principe de gestion des clÃ©s SSH (approche production)
Dans un environnement professionnel, on distingue **deux types de clÃ©s SSH** :
ðŸ”‘ **ClÃ© de build (temporaire)**  
UtilisÃ©e uniquement pour :
  - accÃ©der Ã  la VM lors de sa phase de construction (premier boot)
  - appliquer le hardening CIS via Ansible
  - Supprimer avant la mise en template

ðŸ” **ClÃ© runtime (production)**  
InjectÃ©e dynamiquement lors du dÃ©ploiement final par Terraform.
* Permet d'exÃ©cuter des playbook ansible d'installation,configuration, administration
* Clef permanente qui est le seul moyen de connexion aux VM (aucun mot de passe)

âš ï¸ **Aucune clÃ© SSH de production ne doit Ãªtre figÃ©e dans un template.**  
Pour rappel, la VM template est complÃ¨tement vidÃ© avant sa transformation en template afin de n'avoir aucune clef rÃ©siduelle, c'est Ã  Terraform de gÃ©rer lors du dÃ©ploiement, l'injection des clefs ssh sur les utilisateurs auquel on doit se connecter, ici `ansible` est le seul utilisateur sur lequel on pourra se connecter, uniquement via clef ssh. 

Le workflow est donc le suivant :
1. Injection dâ€™une **clÃ© SSH temporaire** via Cloud-Init
2. DÃ©marrage unique de la VM
3. Application du hardening CIS avec Ansible
4. Suppression de la clÃ© de build et nettoyage Cloud-Init
5. Transformation de la VM en template
6. Injection de la clÃ© SSH dÃ©finitive par Terraform lors du clonage

### 1.4.3) Configuration hyperviseur
PlutÃ´t que d'installer un OS Ã  la main, nous crÃ©ons une **machine "moule"**. Nous prenons un disque dur virtuel dÃ©jÃ  installÃ© par Ubuntu (le fichier `.img`), nous le glissons dans une enveloppe matÃ©rielle virtuelle (la VM), et nous ajoutons un "cerveau de configuration" (**Cloud-Init**). Une fois figÃ©e en **Template**, cette VM ne dÃ©marrera plus jamais, mais servira de source pour cloner les 3 VMs en quelques secondes.

1. Activer le stockage des snippets Cloud-Init
```bash
pvesm set local --content images,rootdir,iso,vztmpl,backup,snippets
mkdir -p /var/lib/vz/snippets
```
2. CrÃ©ation du fichier Cloud-Init de base
```bash
cd /var/lib/vz/snippets
echo "" > /var/lib/vz/snippets/ubuntu-template-build.yaml
nano /var/lib/vz/snippets/ubuntu-template-build.yaml
```

```yaml
#cloud-config
# ==========================================================
# Cloud-Init â€“ Phase BUILD uniquement (Proxmox Cloud-Init)
# ----------------------------------------------------------
# Objectif :
# - Fournir un accÃ¨s SSH TEMPORAIRE pour la phase de build
# - Permettre lâ€™automatisation (Ansible, SSH, provisioning)
# - Installer les composants nÃ©cessaires Ã  Proxmox
#
# Important :
# - Lâ€™utilisateur crÃ©Ã© ici est SUPPRIMÃ‰ avant la conversion
#   de la VM en template
# - La clÃ© SSH associÃ©e est Ã©galement temporaire
# ==========================================================

# ==========================================================
# CrÃ©ation dâ€™un utilisateur temporaire de provisioning
# ==========================================================
users:
  - name: proxmoxinit                     # Utilisateur dÃ©diÃ© au build (non persistant)
    shell: /bin/bash                      # Shell standard pour compatibilitÃ© scripts
    sudo: ALL=(ALL) NOPASSWD:ALL          # Sudo sans mot de passe (automatisation)
    ssh_authorized_keys:
      # ClÃ© SSH TEMPORAIRE utilisÃ©e uniquement pour :
      # - le provisioning
      # - le hardening
      # - la prÃ©paration du template
      - ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIK8iPlirgXN/0JSS/qVpiO+1coIQp866Akv5Ix8G10XR maison

# ==========================================================
# SÃ©curisation de lâ€™accÃ¨s SSH
# ==========================================================

disable_root: true        # DÃ©sactive toute connexion directe en root (CIS / best practice)
ssh_pwauth: false         # DÃ©sactive lâ€™authentification par mot de passe (clÃ© SSH uniquement)

# ==========================================================
# Gestion des mises Ã  jour lors du premier boot
# ==========================================================

package_update: true      # Mise Ã  jour de lâ€™index APT (apt update)
package_upgrade: false    # Pas de upgrade automatique (maÃ®trise des versions)

# ==========================================================
# Paquets requis pour Proxmox
# ==========================================================

packages:
  - qemu-guest-agent      # Agent Proxmox :
                           # - remontÃ©e IP / hostname
                           # - shutdown propre
                           # - meilleure intÃ©gration hyperviseur

# ==========================================================
# Commandes exÃ©cutÃ©es Ã  la fin du cloud-init
# ==========================================================

runcmd:
  # Activation de lâ€™agent Proxmox au dÃ©marrage
  - systemctl enable qemu-guest-agent

  # DÃ©marrage immÃ©diat de lâ€™agent sans reboot
  - systemctl start qemu-guest-agent

```
5. TÃ©lÃ©chargement de lâ€™image Ubuntu Cloud
```bash
cd /tmp
wget https://cloud-images.ubuntu.com/minimal/releases/noble/release/ubuntu-24.04-minimal-cloudimg-amd64.img
```
6. CrÃ©ation de la VM template Proxmox
```bash
qm create 9000 --name ubuntu-2404-template \
  --memory 2048 --cores 2 \
  --cpu host \
  --ostype l26 \
  --net0 virtio,bridge=vmbr0
```
7. Import du disque cloud
```bash
qm importdisk 9000 ubuntu-24.04-minimal-cloudimg-amd64.img local-lvm
```
8. Attachement Cloud-Init et options systÃ¨me
```bash
qm set 9000 \
  --scsihw virtio-scsi-pci \
  --scsi0 local-lvm:vm-9000-disk-0 \
  --ide2 local-lvm:cloudinit \
  --boot order=scsi0 \
  --serial0 socket \
  --vga serial0 \
  --ipconfig0 ip=192.168.122.50/24,gw=192.168.122.1 \
  --nameserver 1.1.1.1 \
  --agent enabled=1 \
  --cicustom "user=local:snippets/ubuntu-template-build.yaml"
```
9. Extension du disque
```
qm disk resize 9000 scsi0 +18G
```
10. DÃ©marrage unique de la VM pour exÃ©cution initiale de cloud-init
```bash
qm start 9000
```
### 1.4.4) Configuration VM template
* Se connecter en SSH sur la VM template 
```bash
ssh proxmoxinit@192.168.122.50
```
8. GÃ©nÃ©rer les clefs SSH hÃ´tes pour Ã©viter l'alerte MITM 
```bash
sudo ssh-keygen -A
```
9. Nettoyage de la VM avant transformation en template
```bash
sudo systemd-run --unit=template-cleanup --collect /bin/bash -c '
pkill -u proxmoxinit || true
sleep 2
userdel -r proxmoxinit || true
cloud-init clean --logs --seed
rm -rf /var/lib/cloud/*
truncate -s 0 /etc/machine-id
rm -f /var/lib/dbus/machine-id
shutdown -h now
'
```
9. Arreter et transformer la VM en template
```bash
qm set 9000 --delete cicustom
qm template 9000
```
> âš ï¸ **Ne jamais transformer une VM en template si elle est en cours dâ€™exÃ©cution**

La VM template est maintenant :
- âœ… Cloud-Init ready
- âœ… SÃ©curisÃ©e (SSH clÃ©-only)
- âœ… Sans Ã©tat applicatif
- âœ… OptimisÃ©e pour le clonage
- âœ… Compatible Terraform / API / GUI

Lors du dÃ©ploiement des VMs finales, **Terraform injectera dynamiquement**
les clÃ©s SSH de production via Cloud-Init, garantissant :
- sÃ©paration build / runtime
- rotation simple des clÃ©s
- conformitÃ© aux bonnes pratiques de sÃ©curitÃ©
# Partie 2 : Infra-as-code Terraform

## 2.1) Outils d'infra-as-code (Terraform vs OpenTofu)
Dans le paradigme DevOps moderne, le dÃ©ploiement manuel d'infrastructures est considÃ©rÃ© comme une **dette technique majeure**. L'instabilitÃ© gÃ©nÃ©rÃ©e par l'erreur humaine, le "configuration drift" (dÃ©rive de configuration) et le manque de reproductibilitÃ© constituent des risques opÃ©rationnels critiques. L'approche **Infrastructure-as-Code (IaC)** rÃ©pond Ã  ces problÃ©matiques en traitant la dÃ©finition du matÃ©riel et du rÃ©seau avec la mÃªme rigueur que le code applicatif.

### 2.1.1) Les piliers thÃ©oriques de l'IaC
L'adoption d'un outil comme Terraform ou OpenTofu repose sur trois concepts fondamentaux que nous avons intÃ©grÃ©s Ã  ce projet :
- **L'Idempotence :** C'est la capacitÃ© de l'outil Ã  exÃ©cuter le mÃªme script plusieurs fois en garantissant un rÃ©sultat identique, sans crÃ©er de doublons ou d'erreurs. Si l'infrastructure cible correspond dÃ©jÃ  Ã  la dÃ©finition du code, l'outil n'entreprend aucune action.
- **L'Approche DÃ©clarative :** Contrairement aux scripts impÃ©ratifs (Bash, Python) oÃ¹ l'on dÃ©crit _comment_ faire (Ã©tapes par Ã©tapes), nous utilisons ici un langage dÃ©claratif pour dÃ©crire _ce que nous voulons_ (l'Ã©tat final). L'outil se charge de calculer la diffÃ©rence entre l'existant et la cible.
- **La Gestion d'Ã‰tat (State Management) :** C'est la "mÃ©moire" de l'infrastructure. Terraform conserve un fichier (`.tfstate`) qui sert de source de vÃ©ritÃ© unique, permettant de mapper les ressources rÃ©elles sur l'hyperviseur Proxmox avec les dÃ©finitions logiques du code.

### 2.1.2) Le langage HCL (HashiCorp Configuration Language)
L'IaC dans ce projet repose sur le **HCL**. Bien que Terraform puisse interprÃ©ter du JSON, le HCL est privilÃ©giÃ© car il offre un Ã©quilibre parfait entre lisibilitÃ© humaine et puissance programmatique. Il permet d'introduire de la logique (boucles `for_each`, structures conditionnelles, variables dynamiques) lÃ  oÃ¹ un format purement sÃ©quentiel Ã©chouerait Ã  gÃ©rer la complexitÃ© d'un cluster Kubernetes.

### 2.1.3) Ã‰tude comparative : La scission Terraform / OpenTofu
Le choix de l'orchestrateur est aujourd'hui marquÃ© par une sÃ©paration nette au sein de l'Ã©cosystÃ¨me open-source :
1. **Terraform (HashiCorp) :** Leader historique et industriel. Son Ã©cosystÃ¨me de "providers" est le plus vaste au monde. Cependant, en aoÃ»t 2023, HashiCorp a fait passer la licence du projet de **MPL** (Mozilla Public License) Ã  la **BUSL** (Business Source License). Ce changement restreint l'usage commercial du code source par des concurrents, transformant Terraform en un produit "source-available" plutÃ´t qu'en un logiciel libre au sens strict.
2. **OpenTofu (Linux Foundation) :** En rÃ©action Ã  ce changement de licence, la communautÃ© et de grandes entreprises (Gruntwork, Spacelift, Harness) ont crÃ©Ã© un "fork" sous l'Ã©gide de la Linux Foundation. OpenTofu est un moteur d'IaC 100% open-source, dirigÃ© par la communautÃ©, qui garantit la neutralitÃ© du projet Ã  long terme.

### 2.1.4) SynthÃ¨se et stratÃ©gie retenue
Le tableau suivant rÃ©sume les critÃ¨res ayant influencÃ© notre choix pour ce projet :

| CritÃ¨re           | Terraform (v1.x)         | OpenTofu (v1.x)                              |
| ----------------- | ------------------------ | -------------------------------------------- |
| **Gouvernance**   | PrivÃ©e (HashiCorp)       | Communautaire (Linux Foundation)             |
| **Licence**       | Semi-propriÃ©taire (BUSL) | Open-Source (Apache 2.0)                     |
| **Ã‰cosystÃ¨me**    | Standard du marchÃ©       | EntiÃ¨rement compatible (Drop-in replacement) |
| **Documentation** | OmniprÃ©sente et Ã©prouvÃ©e | Excellente mais plus rÃ©cente                 |

## 2.2) Solution d'infra-as-code Terraform
Terraform n'agit pas simplement comme un script de crÃ©ation, mais comme un **gestionnaire d'Ã©tat** et un **orchestrateur de ressources**. Son rÃ´le est de traduire nos besoins mÃ©tier (ex: "un cluster Kubernetes de 3 nÅ“uds") en appels API comprÃ©hensibles par l'hyperviseur Proxmox.

### 2.2.1) Provisionnement vs Configuration : La SÃ©paration des ResponsabilitÃ©s
Une confusion classique en ingÃ©nierie DevOps consiste Ã  mÃ©langer le rÃ´le de Terraform avec celui d'Ansible. Pour garantir une infrastructure saine, nous appliquons ici le principe de **SÃ©paration des PrÃ©occupations (Separation of Concerns)** :
- **Terraform (Provisioning) :** Il s'occupe de la couche "basse". Il interagit avec l'hyperviseur pour rÃ©server les ressources physiques (CPU, RAM, Disque, NIC). Il livre une machine "nue" mais accessible via le rÃ©seau.
- **Ansible (Configuration Management) :** Il s'occupe de la couche "haute". Une fois la machine provisionnÃ©e par Terraform, Ansible intervient pour installer les packages, configurer les services (Docker, Kubeadm) et durcir la sÃ©curitÃ© de l'OS.

### 2.2.2) DÃ©composition des Composants de Configuration
Pour que nos machines virtuelles soient optimisÃ©es pour un usage intensif (type cluster Kubernetes), chaque paramÃ¨tre hardware dÃ©fini dans nos fichiers `.tf` a Ã©tÃ© choisi avec prÃ©cision :
- **Ressources de calcul (Compute) :** Nous dÃ©finissons le nombre de _vCPUs_ et de _sockets_. L'utilisation du type de processeur `host` est ici critique : elle permet Ã  la machine virtuelle de voir et d'utiliser les instructions spÃ©cifiques du processeur physique (AES-NI pour le chiffrement, VT-x pour la virtualisation), optimisant ainsi les performances de calcul.
- **Gestion de la MÃ©moire (RAM) :** Au-delÃ  de la simple allocation (ex: 2048 Mo), Terraform permet de gÃ©rer le **Memory Ballooning**. Cette technologie permet Ã  l'hyperviseur de rÃ©cupÃ©rer dynamiquement la mÃ©moire inutilisÃ©e par une VM pour la redistribuer Ã  d'autres, optimisant ainsi la densitÃ© du serveur Proxmox.
- **Sous-systÃ¨me de Stockage (Storage) :** Nous utilisons l'interface **VirtIO SCSI**. C'est le standard de performance pour les environnements virtualisÃ©s Linux, offrant des dÃ©bits supÃ©rieurs et une gestion fine des files d'attente d'E/S (IO Queues). Le choix du _datastore_ (ex: `local-lvm`) dÃ©finit la persistance et la redondance des donnÃ©es.
- **Topologie RÃ©seau (Networking) :** Les VMs sont rattachÃ©es Ã  un pont virtuel (`vmbr0`), agissant comme un commutateur (switch) logiciel. Nous utilisons le modÃ¨le de carte rÃ©seau `virtio` pour minimiser l'overhead CPU lors des transferts de paquets rÃ©seau, ce qui est indispensable pour la communication inter-nÅ“uds d'un cluster.

### 2.2.3) Cloud-Init : Le pont entre Hardware et Software
Le composant le plus stratÃ©gique de notre configuration Terraform est le bloc **Cloud-Init**. Sans lui, la VM crÃ©Ã©e reste une "boÃ®te noire" inaccessible. Cloud-init permet d'injecter des mÃ©tadonnÃ©es dÃ¨s le premier dÃ©marrage :
1. **Bootstrapping RÃ©seau :** Configuration de l'IP statique et de la passerelle (Gateway) pour assurer la connectivitÃ© immÃ©diate.
2. **Authentification :** Injection de clÃ©s publiques SSH, rendant tout mot de passe obsolÃ¨te et sÃ©curisant l'accÃ¨s dÃ¨s la premiÃ¨re seconde.
3. **Personnalisation OS :** CrÃ©ation de l'utilisateur systÃ¨me `ansible` et mise Ã  jour des dÃ©pÃ´ts.

### 2.2.4) Le Cycle de Vie d'une Ressource
Terraform gÃ¨re ce que l'on appelle le **Resource Graph**. Il comprend les dÃ©pendances entre les objets (ex: ne pas configurer le rÃ©seau tant que la VM n'est pas crÃ©Ã©e). Ce cycle se dÃ©compose en quatre phases :

| Phase       | Action Technique                             | RÃ©sultat                                                 |
| ----------- | -------------------------------------------- | -------------------------------------------------------- |
| **Refresh** | Lecture de l'Ã©tat actuel sur Proxmox.        | Synchronisation du fichier `.tfstate`.                   |
| **Plan**    | Comparaison entre le code HCL et la rÃ©alitÃ©. | GÃ©nÃ©ration d'un diffÃ©rentiel (calcul des modifications). |
| **Apply**   | Appels API vers Proxmox (POST/PUT).          | CrÃ©ation ou modification des VMs.                        |
| **Destroy** | Suppression propre des ressources (DELETE).  | LibÃ©ration des ressources de l'hyperviseur.              |

## 2.3) Choix du provider terraform proxmox : telmate vs bpg
Le **Provider** constitue la couche d'abstraction logicielle indispensable Ã  Terraform. Son rÃ´le est de traduire les ressources dÃ©finies en HCL en appels de mÃ©thodes de l'API REST de Proxmox VE. Dans le cadre de ce projet, le choix du provider n'est pas une simple prÃ©fÃ©rence syntaxique, mais une dÃ©cision stratÃ©gique impactant la stabilitÃ© du cycle de vie de nos machines virtuelles.

### 2.3.1) Provider Telmate (`telmate/proxmox`)
Historiquement, le provider Telmate a Ã©tÃ© le pionnier de l'IaC pour Proxmox. Cependant, l'Ã©volution technologique de l'hyperviseur (notamment depuis Proxmox 8.x et l'actuelle 9.x) a mis en exergue des limites structurelles :
- **Dette Technique et API Legacy :** Telmate repose sur des bibliothÃ¨ques de communication vieillissantes qui peinent Ã  interprÃ©ter les nouvelles rÃ©ponses JSON de l'API Proxmox. Cela se traduit souvent par des erreurs de "parsing" lors du dÃ©ploiement.
- **Le ProblÃ¨me du "State Drift" (DÃ©rive d'Ã©tat) :** L'une des faiblesses majeures de Telmate rÃ©side dans sa gestion des chaÃ®nes de caractÃ¨res pour Cloud-Init (ex: le paramÃ¨tre `ipconfig0`). Terraform n'Ã©tant pas capable de valider structurellement ces chaÃ®nes, il dÃ©tecte frÃ©quemment des changements fictifs entre le code et la rÃ©alitÃ©, forÃ§ant des recrÃ©ations de VMs non souhaitÃ©es.
- **Manque de GranularitÃ© :** La dÃ©finition des ressources (disques, rÃ©seaux) est souvent globale et peu flexible, rendant difficile la gestion de configurations complexes comme le multi-disque ou les interfaces rÃ©seau avancÃ©es.

### 2.3.2) Le Provider BPG (`bpg/proxmox`)
Le provider **BPG** (en version **0.90.0** pour ce projet) reprÃ©sente une rupture technologique. Il a Ã©tÃ© conÃ§u avec une approche "Cloud-Native" pour offrir une paritÃ© quasi totale avec les fonctionnalitÃ©s de l'interface graphique de Proxmox.
- **Architecture TypÃ©e et SchÃ©mas HCL2 :** Contrairement Ã  son prÃ©dÃ©cesseur, BPG utilise des blocs de configuration fortement typÃ©s. Au lieu de passer des arguments sous forme de texte brut, nous dÃ©finissons des objets (blocs `disk`, `network_device`, `initialization`). Cela permet Ã  Terraform de valider la syntaxe et la logique des ressources localement avant d'envoyer la moindre requÃªte Ã  l'hyperviseur.
- **Gestion Native de Cloud-Init :** BPG traite Cloud-Init comme une entitÃ© structurÃ©e. Il gÃ¨re intelligemment la gÃ©nÃ©ration du lecteur CD-ROM Cloud-Init et l'injection des donnÃ©es (utilisateurs, clÃ©s SSH, rÃ©seaux), garantissant que la VM est configurÃ©e correctement dÃ¨s le premier "boot" sans intervention manuelle.
- **ContrÃ´le fin du Cycle de Vie :** Il permet des opÃ©rations de maintenance avancÃ©es, comme le redimensionnement de disques Ã  chaud ou la modification de la mÃ©moire sans interruption de service, lÃ  oÃ¹ d'autres providers imposeraient un redÃ©marrage.

### 2.3.3) SynthÃ¨se Technique et Comparaison
Le tableau ci-dessous expose les diffÃ©rentiels techniques observÃ©s lors de nos tests comparatifs :

| CaractÃ©ristique               | Telmate (Legacy)                       | BPG (Moderne / Retenu)                      |
| ----------------------------- | -------------------------------------- | ------------------------------------------- |
| **CompatibilitÃ© Proxmox 8/9** | Instable (Bugs d'API frÃ©quents)        | Native (OptimisÃ©e pour le SDK Go)           |
| **Logique de Configuration**  | OrientÃ©e "Attributs" (Strings)         | OrientÃ©e "Blocs" (Objets typÃ©s)             |
| **Gestion des Disques**       | Rigide (souvent limitÃ©e Ã  1-2 disques) | Granulaire (Support illimitÃ©, types variÃ©s) |
| **StabilitÃ© du State**        | Sujet au "Drift" intempestif           | Haute fidÃ©litÃ© entre Code et RÃ©alitÃ©        |
| **Interface API**             | API REST v1 (limitÃ©e)                  | API REST v2 (complÃ¨te)                      |

### 2.3.4) Justification du Choix Final
Pour ce projet de dÃ©ploiement d'un cluster Kubernetes, la fiabilitÃ© du rÃ©seau et du stockage est non nÃ©gociable. Le choix du provider **BPG 0.90.0** s'est imposÃ© pour trois raisons majeures :
1. **PrÃ©visibilitÃ© :** La capacitÃ© de BPG Ã  reflÃ©ter exactement l'Ã©tat de la VM dans le `terraform.tfstate` Ã©limine les comportements erratiques lors des phases de mise Ã  jour (`apply`).
2. **SÃ©curitÃ© :** L'injection rigoureuse des clÃ©s SSH via le bloc `user_account` de Cloud-Init assure une surface d'attaque rÃ©duite dÃ¨s le provisionnement.
3. **Performance :** L'utilisation de l'interface VirtIO SCSI et du type CPU `host`, parfaitement supportÃ©s par BPG, garantit que nos nÅ“uds Kubernetes disposent des performances maximales offertes par l'hyperviseur.

> **Conclusion :** En migrant notre infrastructure de Telmate vers BPG, nous passons d'un bricolage de scripts Ã  une vÃ©ritable solution d'**Infrastructure-as-Code de classe entreprise**, prÃªte pour la production et facile Ã  maintenir.

## 2.4) SchÃ©ma d'architecture deployÃ©e
{IMAGE DU LAB COMPLET}
## 2.5) CrÃ©ation compte et token Terraform
* Configuration du compte terraform, associÃ© Ã  un rÃ´le avec les droits et un token reliÃ©.
```bash
pveum user add terraform@pve
pveum role add Terraform -privs "Realm.AllocateUser, VM.PowerMgmt, VM.GuestAgent.Unrestricted, Sys.Console, Sys.Audit, Sys.AccessNetwork, VM.Config.Cloudinit, VM.Replicate, Pool.Allocate, SDN.Audit, Realm.Allocate, SDN.Use, Mapping.Modify, VM.Config.Memory, VM.GuestAgent.FileSystemMgmt, VM.Allocate, SDN.Allocate, VM.Console, VM.Clone, VM.Backup, Datastore.AllocateTemplate, VM.Snapshot, VM.Config.Network, Sys.Incoming, Sys.Modify, VM.Snapshot.Rollback, VM.Config.Disk, Datastore.Allocate, VM.Config.CPU, VM.Config.CDROM, Group.Allocate, Datastore.Audit, VM.Migrate, VM.GuestAgent.FileWrite, Mapping.Use, Datastore.AllocateSpace, Sys.Syslog, VM.Config.Options, Pool.Audit, User.Modify, VM.Config.HWType, VM.Audit, Sys.PowerMgmt, VM.GuestAgent.Audit, Mapping.Audit, VM.GuestAgent.FileRead, Permissions.Modify"
pveum aclmod / -user terraform@pve -role Terraform
pveum user token add terraform@pve provider --privsep=0
```

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚ key          â”‚ value                             
â•žâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”‚ full-tokenid â”‚ terraform@pve!provider            
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚ info         â”‚ {"privsep":"0"}                   
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚ value        â”‚ 3e93580b-12be-4e93-b0a0-a2f1c3e2de
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

## 2.6) Installation des outils Terraform/OpenTofu

### 2.6.1) Installation de Terraform
```bash
sudo apt-get update && sudo apt-get install -y gnupg software-properties-common

wget -O- https://apt.releases.hashicorp.com/gpg | \
gpg --dearmor | \
sudo tee /usr/share/keyrings/hashicorp-archive-keyring.gpg > /dev/null

gpg --no-default-keyring \
--keyring /usr/share/keyrings/hashicorp-archive-keyring.gpg \
--fingerprint

echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] https://apt.releases.hashicorp.com $(grep -oP '(?<=UBUNTU_CODENAME=).*' /etc/os-release || lsb_release -cs) main" | sudo tee /etc/apt/sources.list.d/hashicorp.list

sudo apt update

sudo apt-get install terraform
```
* VÃ©rification de l'installation
```bash
terraform version

Terraform v1.14.3
on linux_amd64
```
### 2.6.2) Installation de OpenTofu
```bash
# Download the installer script:
curl --proto '=https' --tlsv1.2 -fsSL https://get.opentofu.org/install-opentofu.sh -o install-opentofu.sh
# Alternatively: wget --secure-protocol=TLSv1_2 --https-only https://get.opentofu.org/install-opentofu.sh -O install-opentofu.sh

# Give it execution permissions:
chmod +x install-opentofu.sh

# Please inspect the downloaded script

# Run the installer:
./install-opentofu.sh --install-method deb

# Remove the installer:
rm -f install-opentofu.sh
```
* VÃ©rification de l'installation
```bash
tofu --version

OpenTofu v1.11.2
on linux_amd64

```
## 2.7) DÃ©ploiement de 4 VMs template 
* Remise Ã  zÃ©ro de l'environnement Terraform et les historiques
```bash
cd ~/devops/terraform/
rm -rf .terraform
rm -f .terraform.lock.hcl
rm -f terraform.tfstate terraform.tfstate.backup
rm -rf .terraform .terraform.lock.hcl
```
* Execution du dÃ©ploiement de l'infrastructure
```
terraform init
terraform plan
terraform apply
```
* Extrait des retours terraform
```bash
proxmox_virtual_environment_vm.vm[0]: Creation complete after 53s [id=9100]
proxmox_virtual_environment_vm.vm[1]: Creation complete after 54s [id=9101]
proxmox_virtual_environment_vm.vm[3]: Creation complete after 55s [id=9103]
proxmox_virtual_environment_vm.vm[2]: Creation complete after 56s [id=9102]

Apply complete! Resources: 5 added, 0 changed, 0 destroyed.

Outputs:

db_ip = "192.168.122.153"
master_ip = "192.168.122.150"
worker_ips = [
  "192.168.122.151",
  "192.168.122.152",
]
```
* Suppression de l'infrastructure dÃ©ployÃ© 
```bash
terraform destroy
```
* Test de connexion sur les VM depuis le poste d'administration
```bash
ssh ansible@192.168.122.150 #VM Master
ssh ansible@192.168.122.151 #VM Node1
ssh ansible@192.168.122.152 #VM Node2
ssh ansible@192.168.122.153 #VM DB
```
# Partie 3 : Automatisation et configuration systÃ¨me (Ansible)
## 3.1) Notion dâ€™automatisation de configuration
Dans la continuitÃ© de la dÃ©marche DevOps adoptÃ©e dans ce projet, lâ€™automatisation de la configuration des systÃ¨mes constitue un enjeu central. Lorsquâ€™un environnement comporte plusieurs machines â€” virtuelles dans notre cas â€” il devient rapidement difficile, voire risquÃ©, de maintenir une homogÃ©nÃ©itÃ© de configuration par des actions manuelles. Chaque intervention humaine augmente le risque dâ€™erreur, de dÃ©rive de configuration (_configuration drift_) et rend la reproductibilitÃ© de lâ€™infrastructure plus complexe.

Câ€™est dans ce contexte quâ€™intervient **Ansible**, un outil dâ€™automatisation et de gestion de configuration largement utilisÃ© dans les environnements professionnels. Ansible permet de dÃ©crire, sous forme dÃ©clarative, lâ€™Ã©tat souhaitÃ© dâ€™un systÃ¨me et dâ€™automatiser lâ€™exÃ©cution de tÃ¢ches sur un ensemble de machines distantes. Contrairement Ã  dâ€™autres outils du mÃªme domaine, Ansible adopte une approche dite _agentless_ : aucune installation spÃ©cifique nâ€™est requise sur les machines cibles. Les opÃ©rations sont rÃ©alisÃ©es principalement via des connexions SSH, ce qui simplifie considÃ©rablement le dÃ©ploiement et la maintenance de la solution.

Le fonctionnement dâ€™Ansible repose sur des **playbooks**, qui sont des fichiers dÃ©crits en YAML. Un playbook correspond Ã  un enchaÃ®nement structurÃ© de tÃ¢ches (_tasks_), chacune dÃ©crivant une action Ã  effectuer sur un ou plusieurs hÃ´tes : installation de paquets, modification de fichiers de configuration, gestion de services, exÃ©cution de commandes, etc. Lâ€™un des principes fondamentaux dâ€™Ansible est lâ€™**idempotence** : une tÃ¢che peut Ãªtre exÃ©cutÃ©e plusieurs fois sans modifier lâ€™Ã©tat du systÃ¨me si celui-ci correspond dÃ©jÃ  Ã  lâ€™Ã©tat attendu. Cette propriÃ©tÃ© est essentielle pour garantir des dÃ©ploiements fiables, rÃ©pÃ©tables et non destructifs.

Dans le cadre de ce laboratoire, Ansible a Ã©tÃ© utilisÃ© comme **outil dâ€™orchestration de la configuration** des diffÃ©rentes machines virtuelles composant lâ€™infrastructure Kubernetes. Il permet notamment dâ€™automatiser des opÃ©rations qui seraient fastidieuses et sources dâ€™erreurs si elles Ã©taient rÃ©alisÃ©es manuellement, tout en offrant un retour prÃ©cis sur lâ€™Ã©tat dâ€™exÃ©cution de chaque tÃ¢che (succÃ¨s, modification, Ã©chec, ou action ignorÃ©e).

Les cas dâ€™usage dâ€™Ansible dans ce projet illustrent bien la polyvalence de lâ€™outil. Il a tout dâ€™abord Ã©tÃ© employÃ© pour des tÃ¢ches de **prÃ©paration et de durcissement des systÃ¨mes**. Dans un contexte professionnel, le niveau de sÃ©curitÃ© dâ€™un systÃ¨me dâ€™exploitation est souvent Ã©valuÃ© Ã  lâ€™aide de rÃ©fÃ©rentiels tels que les _CIS Benchmarks_ (Center for Internet Security). Ces rÃ©fÃ©rentiels dÃ©finissent un ensemble de bonnes pratiques de configuration visant Ã  rÃ©duire la surface dâ€™attaque dâ€™un systÃ¨me. Bien que le prÃ©sent projet soit rÃ©alisÃ© dans un cadre de laboratoire, Ansible permettrait trÃ¨s facilement dâ€™implÃ©menter automatiquement ces recommandations Ã  grande Ã©chelle, en sâ€™appuyant sur des playbooks communautaires existants. Les benchmarks CIS sont gÃ©nÃ©ralement dÃ©clinÃ©s en plusieurs niveaux, allant dâ€™un niveau 1, axÃ© sur une sÃ©curitÃ© de base sans impact significatif sur lâ€™exploitation, Ã  un niveau 2, plus restrictif et destinÃ© Ã  des environnements oÃ¹ la sÃ©curitÃ© prime sur le confort dâ€™utilisation.

Ansible a Ã©galement Ã©tÃ© utilisÃ© pour lâ€™**installation et la configuration de services applicatifs**. Dans ce projet, cela inclut notamment le dÃ©ploiement des composants nÃ©cessaires au cluster Kubernetes (nÅ“ud maÃ®tre, nÅ“uds workers), lâ€™installation dâ€™outils complÃ©mentaires comme MetalLB, lâ€™ingress NGINX ou encore le serveur de mÃ©triques (_metrics-server_). Chaque service est dÃ©ployÃ© de maniÃ¨re contrÃ´lÃ©e, reproductible et cohÃ©rente sur lâ€™ensemble du cluster, ce qui permet de reconstruire intÃ©gralement lâ€™infrastructure Ã  partir des playbooks sans intervention manuelle.

Enfin, Ansible sâ€™avÃ¨re particuliÃ¨rement adaptÃ© Ã  la **gestion des tÃ¢ches dâ€™administration courantes**. Il est frÃ©quent de crÃ©er des playbooks dÃ©diÃ©s Ã  des opÃ©rations spÃ©cifiques telles que la mise Ã  jour des systÃ¨mes, la modification centralisÃ©e de fichiers de configuration, la gestion des utilisateurs ou encore la mise en place de procÃ©dures de sauvegarde. Dans le cadre de ce laboratoire, cette logique a Ã©tÃ© appliquÃ©e pour structurer le dÃ©ploiement de Wiki.js en plusieurs phases distinctes : une phase dâ€™initialisation permettant lâ€™installation et la configuration initiale de lâ€™application, suivie dâ€™une phase de mise Ã  lâ€™Ã©tat final intÃ©grant la montÃ©e en charge et lâ€™activation de lâ€™autoscaling.

Le ciblage des machines sur lesquelles sâ€™exÃ©cutent les playbooks est assurÃ© par un **systÃ¨me dâ€™inventaire**. Lâ€™inventaire Ansible est gÃ©nÃ©ralement dÃ©fini dans un fichier, souvent nommÃ© `inventory.ini`, qui regroupe les hÃ´tes par catÃ©gories fonctionnelles (par exemple : nÅ“ud maÃ®tre, nÅ“uds workers, base de donnÃ©es). Cette organisation permet dâ€™appliquer un playbook Ã  un sous-ensemble prÃ©cis de lâ€™infrastructure. Dans ce projet, lâ€™inventaire Ansible nâ€™est pas dÃ©fini manuellement : il est gÃ©nÃ©rÃ© automatiquement Ã  partir des sorties de Terraform (ou OpenTofu), garantissant ainsi une cohÃ©rence totale entre la phase de provisionnement des machines virtuelles et la phase de configuration logicielle.

Lâ€™installation dâ€™Ansible sur le poste dâ€™administration est relativement simple et illustre lâ€™accessibilitÃ© de lâ€™outil :
```bash
sudo apt install ansible
```
En rÃ©sumÃ©, Ansible joue dans ce projet un rÃ´le clÃ© en tant que **chaÃ®non entre lâ€™infrastructure virtuelle provisionnÃ©e par Terraform et les services applicatifs dÃ©ployÃ©s sur Kubernetes**. Il permet de traduire une architecture thÃ©orique en une infrastructure fonctionnelle, reproductible et documentÃ©e, tout en sâ€™inscrivant pleinement dans les bonnes pratiques DevOps modernes.

## 3.2) Structuration des playbooks et logique dâ€™exÃ©cution
Afin de rendre le dÃ©ploiement reproductible et lisible, le rÃ©pertoire `ansible/` est organisÃ© autour dâ€™une sÃ©rie de playbooks numÃ©rotÃ©s, reflÃ©tant lâ€™ordre dâ€™exÃ©cution nÃ©cessaire Ã  la mise en service complÃ¨te du laboratoire. Cette numÃ©rotation nâ€™est pas purement esthÃ©tique : elle matÃ©rialise les dÃ©pendances techniques entre composants. Certaines briques ne peuvent Ãªtre configurÃ©es que si les prÃ©cÃ©dentes sont opÃ©rationnelles (par exemple, un service applicatif ne peut Ãªtre exposÃ© via un Ingress que si un contrÃ´leur Ingress est installÃ©, et lâ€™autoscaling via HPA nâ€™est possible que si les mÃ©triques sont disponibles).

Le premier playbook, `1-deploy-k8s-master.yaml`, Ã©tablit les fondations du cluster Kubernetes. Il prÃ©pare le nÅ“ud maÃ®tre (control plane), installe les dÃ©pendances nÃ©cessaires, initialise le cluster (kubeadm) et met en place lâ€™accÃ¨s administratif (kubeconfig) afin de permettre lâ€™administration via `kubectl`. Ã€ lâ€™issue de cette Ã©tape, le cluster existe, mais il nâ€™est pas encore pleinement exploitable tant que des nÅ“uds de calcul nâ€™ont pas Ã©tÃ© joints et quâ€™un plugin rÃ©seau nâ€™assure pas la connectivitÃ© inter-pods.

Le playbook `2-deploy-k8s-workers.yaml` poursuit logiquement en ajoutant les nÅ“uds workers au cluster. Cette Ã©tape automatise la jonction des nÅ“uds au control plane et garantit que lâ€™ensemble des machines prÃ©vues participe bien Ã  lâ€™exÃ©cution des charges de travail. Ã€ ce stade, le cluster devient distribuÃ© et capable dâ€™hÃ©berger des applications, mais lâ€™environnement nâ€™est pas encore complet sur le plan â€œplateformeâ€, car il manque les briques nÃ©cessaires Ã  lâ€™exposition rÃ©seau et Ã  certains services transverses.

Le playbook `3-deploy-db-postgres.yaml` dÃ©ploie ensuite la base de donnÃ©es PostgreSQL sur une machine dÃ©diÃ©e, hors du cluster Kubernetes. Ce choix permet de dÃ©coupler le stockage persistant du cycle de vie des pods et de simplifier la gestion de la donnÃ©e dans un contexte de laboratoire (stabilitÃ©, visibilitÃ©, dÃ©pannage facilitÃ©). Le playbook prÃ©pare le service de base de donnÃ©es (crÃ©ation de la base, utilisateur, mot de passe et paramÃ¨tres), puis vÃ©rifie que lâ€™instance est accessible depuis le cluster. Cette Ã©tape est volontairement placÃ©e avant le dÃ©ploiement applicatif afin que Wiki.js puisse se connecter Ã  une base dÃ©jÃ  prÃªte et stable.

Le playbook `4-deploy-metallb.yaml` ajoute une brique essentielle dans un environnement on-premise : la capacitÃ© Ã  disposer de Services Kubernetes de type `LoadBalancer`. Dans les clouds publics, cette fonctionnalitÃ© est fournie nativement par lâ€™infrastructure. Dans un lab local, MetalLB remplit ce rÃ´le en attribuant des adresses IP virtuelles Ã  certains services, offrant ainsi une exposition rÃ©seau â€œpropreâ€ et cohÃ©rente avec les standards Kubernetes. Cette Ã©tape est positionnÃ©e avant lâ€™ingress car le contrÃ´leur Ingress doit Ãªtre exposÃ© vers lâ€™extÃ©rieur via un service `LoadBalancer` (ou Ã©quivalent).

Le playbook `5-deploy-ingress-nginx.yaml` installe ensuite le contrÃ´leur Ingress NGINX. Il constitue le point dâ€™entrÃ©e HTTP/HTTPS du cluster et permet de router les requÃªtes vers les services applicatifs internes selon un modÃ¨le standard (host/path). Lâ€™Ingress Controller est un composant structurant : sans lui, lâ€™accÃ¨s aux applications se ferait via des NodePorts ou des port-forwardings, ce qui est moins reprÃ©sentatif des architectures rÃ©elles. Une fois cette brique en place, le cluster dispose dâ€™un mÃ©canisme stable pour publier des applications via un nom de domaine et des rÃ¨gles de routage.

Le playbook `6-deploy-metrics-server.yaml` complÃ¨te la couche â€œplateformeâ€ en installant `metrics-server`, qui expose les mÃ©triques CPU/RAM via lâ€™API `metrics.k8s.io`. Cette brique est indispensable pour deux raisons : dâ€™une part pour diagnostiquer et observer la consommation de ressources (`kubectl top`), et dâ€™autre part pour activer lâ€™autoscaling horizontal (HPA). Lâ€™ordre est important : lâ€™HPA ne peut pas fonctionner tant que les mÃ©triques ne sont pas disponibles et stabilisÃ©es.

Le playbook `7-deploy-wikijs-init.yaml` dÃ©ploie ensuite Wiki.js via Helm dans une configuration dâ€™initialisation. La logique est volontairement prudente : conformÃ©ment aux recommandations Wiki.js, une instance unique est utilisÃ©e lors de la phase de setup afin dâ€™Ã©viter des comportements incohÃ©rents (initialisation concurrente, Ã©tats de configuration divergents). Le playbook automatise lâ€™installation (chart Helm, namespace, valeurs de configuration, connexion Ã  la base externe et crÃ©ation de lâ€™Ingress), puis sâ€™arrÃªte volontairement au moment oÃ¹ lâ€™interface web est accessible pour finaliser la configuration initiale via lâ€™assistant de setup.

Enfin, `8-deploy-wikijs-scale.yaml` correspond Ã  la mise en â€œconfiguration finaleâ€ du service. Une fois lâ€™initialisation validÃ©e, ce playbook applique les paramÃ¨tres de montÃ©e en charge : augmentation du nombre de rÃ©plicas, dÃ©finition de ressources minimales/maximales et, si souhaitÃ©, activation dâ€™un autoscaler (HPA) avec un seuil de dÃ©clenchement basÃ© sur lâ€™utilisation CPU. Cette sÃ©paration en deux playbooks (init vs scale) reflÃ¨te une logique proche des pratiques industrielles : on distingue une phase de bootstrap contrÃ´lÃ©e dâ€™une phase dâ€™exploitation et de dimensionnement.

Ainsi, lâ€™enchaÃ®nement des playbooks ne correspond pas seulement Ã  une progression technique, mais Ã  une structuration mÃ©thodique : dâ€™abord la crÃ©ation du cluster, ensuite les services â€œplateformeâ€ nÃ©cessaires (rÃ©seau, exposition, observabilitÃ©), puis le dÃ©ploiement applicatif avec une phase dâ€™initialisation maÃ®trisÃ©e, et enfin la mise Ã  lâ€™Ã©chelle. Cette approche permet dâ€™obtenir un laboratoire reproductible, stable et proche des architectures observÃ©es en production.
```
ansible/
â”œâ”€â”€ 1-deploy-k8s-master.yaml
â”œâ”€â”€ 2-deploy-k8s-workers.yaml
â”œâ”€â”€ 3-deploy-db-postgres.yaml
â”œâ”€â”€ 4-deploy-metallb.yaml
â”œâ”€â”€ 5-deploy-ingress-nginx.yaml
â”œâ”€â”€ 6-deploy-metrics-server.yaml
â”œâ”€â”€ 7-deploy-wikijs-init.yaml
â”œâ”€â”€ 8-deploy-wikijs-scale.yaml
â”œâ”€â”€ artifacts
â”‚Â Â  â””â”€â”€ join-workers.sh
â”œâ”€â”€ cis_ubuntu24_audit.yml
â”œâ”€â”€ inventory.ini
â”œâ”€â”€ inventory.template.ini
â”œâ”€â”€ reports
â”‚Â Â  â”œâ”€â”€ tf-k8s-master
â”‚Â Â  â”‚Â Â  â””â”€â”€ cis_audit_result_03_01_2026_18h08.txt
â”‚Â Â  â”œâ”€â”€ tf-k8s-node-1
â”‚Â Â  â”‚Â Â  â””â”€â”€ cis_audit_result_03_01_2026_18h08.txt
â”‚Â Â  â””â”€â”€ tf-k8s-node-2
â”‚Â Â      â””â”€â”€ cis_audit_result_03_01_2026_18h08.txt
â”œâ”€â”€ roles
â”‚Â Â  â”œâ”€â”€ ubuntu24_cis
â”‚Â Â  â””â”€â”€ ubuntu24_cis_audit
â”œâ”€â”€ terraform.tfstate
```
## 3.3) Tache 0 : Audit du niveau de sÃ©curitÃ© CIS (optionnnel)
 Il existe plusieurs outils pour connaitre son niveaux de conformitÃ© face aux benchmarks CIS, certains sont payants d'autres complÃ¨tement open-source et gratuit et certains se basent sur d'autres critÃ¨res. Dans notre cas nous utiliserons l'outil de vÃ©rification : 
 * UBUNTU24-CIS-Audit (GOSS) : L'outil directement fournit avec notre playbook d'hardening ansible fait par `Ansible-lockdown`, il permet de vÃ©rifier le niveau de conformitÃ© avec tous les dÃ©tails nÃ©cessaire

Il faut donc installer via Ansible les outils pour effectuer le scoring sur chaque VM 

Le but ici est de dÃ©ployer sur l'ensemble des VMs du cluster l'outil `UBUNTU24-CIS-Audit` pour connaitre leur score de conformitÃ© et ensuite comparer l'Ã©volution aprÃ¨s la phase de hardening. Pour cela nous avons mis en place un playbook ansible qui se connecte en SSH sur les agents et va venir effectuer ces actions : 
0. Installer rsync pour le transfert
1. PrÃ©parer l'environnement d'audit
2. TÃ©lÃ©charger le binaire GOSS
3. Synchroniser les tests CIS
4. Lancer l'audit CIS (Format Documentation)
5. Localiser le rapport gÃ©nÃ©rÃ© par le script
6. CrÃ©er le dossier de stockage local
7. Rapatrier le rapport avec date au format franÃ§ais
8. RÃ©sumÃ© de l'audit

Et nous aurons Ã  la toute fin un fichier pour chaque VMs avec le rapport complet avec la date. Nous pouvons le conserver histoire d'avoir un historique du niveau de sÃ©curitÃ© ou bien prouvÃ© par la suite que le hardening a bien fonctionnÃ©.

* ExÃ©cution du playbook
```bash
cd ~/devops/ansible
ansible-playbook -i inventory.ini cis_ubuntu24_audit.yml
```
* Consulter les rapports gÃ©nÃ©rÃ©s avec les dÃ©tails + score Ã  la fin.
```bash
tree reports/
reports/
â”œâ”€â”€ tf-k8s-master
â”‚Â Â  â””â”€â”€ cis_audit_result_03_01_2026_00h17.txt
â”œâ”€â”€ tf-k8s-node-1
â”‚Â Â  â””â”€â”€ cis_audit_result_03_01_2026_00h17.txt
â””â”€â”€ tf-k8s-node-2
    â””â”€â”€ cis_audit_result_03_01_2026_00h17.txt
```

| Score   | Avant hardening | AprÃ¨s hardening |
| ------- | --------------- | --------------- |
| Failed  | 338             | 74              |
| Success | 368             | 665             |
| Skipped | 50              | 17              |
| Total   | 756             | 756             |
| **%**   | **48,7 %**      | **88,0 %**      |
# Partie 4 : Solution de conteneurisation (Podman)  
## 4.1) Notion de conteneurisation
La conteneurisation reprÃ©sente une Ã©volution majeure de la virtualisation, se distinguant de la virtualisation matÃ©rielle classique (Hyperviseurs de Type 1 ou 2) par son niveau d'abstraction. Tandis qu'une machine virtuelle Ã©mule un matÃ©riel complet, incluant un BIOS/UEFI et un systÃ¨me d'exploitation invitÃ© intÃ©gral avec son propre noyau, le conteneur opÃ¨re une **virtualisation au niveau du systÃ¨me d'exploitation**.

Cette technologie repose sur une exploitation fine des primitives du noyau Linux (Kernel), permettant d'isoler des processus tout en partageant les ressources de la machine hÃ´te. Cette isolation est rendue possible par la synergie de trois piliers techniques fondamentaux :
- **Les Namespaces (Espaces de nommage) :** Ils constituent la barriÃ¨re d'isolation principale en cloisonnant les ressources systÃ¨me par processus. Le noyau alloue Ã  chaque conteneur ses propres instances de structures de donnÃ©es (PID pour les processus, NET pour la pile rÃ©seau, MNT pour les points de montage, UTS pour le nom d'hÃ´te et IPC pour les communications inter-processus). De fait, un processus Ã  l'intÃ©rieur d'un conteneur "croit" Ãªtre seul sur le systÃ¨me, sans visibilitÃ© sur l'hÃ´te ou les autres conteneurs.
- **Les Control Groups (cgroups) :** Si les namespaces isolent ce que le conteneur peut "voir", les cgroups limitent ce qu'il peut "consommer". Ils permettent une gestion granulaire des ressources (CPU, RAM, I/O disque, bande passante rÃ©seau), garantissant qu'un conteneur ne puisse pas saturer l'hÃ´te et provoquer un dÃ©ni de service pour les autres applications (phÃ©nomÃ¨ne du "noisy neighbor").
- **Le SystÃ¨me de Fichiers en Couches (UnionFS / Overlay2) :** Contrairement aux images de VM lourdes et monolithiques, les conteneurs utilisent des systÃ¨mes de fichiers d'union. Chaque modification est une couche supplÃ©mentaire (layer) empilÃ©e sur une image de base immuable. Cette architecture permet une optimisation massive du stockage par dÃ©duplication et accÃ©lÃ¨re drastiquement le dÃ©ploiement via le mÃ©canisme de "Copy-on-Write" (CoW).

En somme, le conteneur devient une unitÃ© de distribution logicielle universelle. En encapsulant l'application avec l'intÃ©gralitÃ© de ses dÃ©pendances (librairies, binaires, fichiers de configuration), nous Ã©liminons l'adage "Ã§a marche sur ma machine" pour garantir une stricte paritÃ© entre les environnements de dÃ©veloppement, de qualification et de production.

## 4.2) Etudes des solutions de conteneurisation (docker vs podman)
Le choix du moteur d'exÃ©cution (runtime) est une dÃ©cision architecturale critique qui conditionne la sÃ©curitÃ©, la rÃ©silience et l'opÃ©rabilitÃ© de notre infrastructure. Historiquement, **Docker** a dÃ©mocratisÃ© l'usage des conteneurs en proposant une interface simplifiÃ©e. Toutefois, l'Ã©volution des exigences de sÃ©curitÃ© et l'Ã©mergence des standards de l'OCI (Open Container Initiative) ont mis en lumiÃ¨re des limites structurelles que **Podman** (Pod Manager) vient corriger.

### 4.2.1) L'architecture monolithique de Docker et ses vecteurs de risques
L'architecture de Docker repose sur un modÃ¨le client-serveur centralisÃ© autour du dÃ©mon `dockerd`. Lorsqu'un utilisateur invoque la commande `docker run`, le client CLI communique via une socket locale (ou rÃ©seau) avec ce dÃ©mon qui possÃ¨de les privilÃ¨ges `root`. Cette conception prÃ©sente trois vulnÃ©rabilitÃ©s majeures :

1. **Le Point de DÃ©faillance Unique (SPOF) :** En tant que processus monolithique, le dÃ©mon Docker gÃ¨re tout : l'Ã©tat des conteneurs, les images, les volumes et le rÃ©seau. Si le processus `dockerd` s'interrompt, l'intÃ©gralitÃ© de la flotte de conteneurs devient orpheline ou s'arrÃªte, ce qui est incompatible avec une haute disponibilitÃ© rigoureuse.
2. **L'exposition de la surface d'attaque (Root-DÃ¦mon) :** Le fait que le moteur de conteneurisation s'exÃ©cute en permanence avec des privilÃ¨ges Ã©levÃ©s crÃ©e une faille de sÃ©curitÃ© critique. Si un attaquant parvient Ã  compromettre le dÃ©mon ou Ã  s'en Ã©chapper via une vulnÃ©rabilitÃ© de type "container escape", il obtient immÃ©diatement un accÃ¨s privilÃ©giÃ© total sur l'hÃ´te physique ou virtuel.
3. **L'obsolescence face Ã  l'Ã©cosystÃ¨me Kubernetes :** Initialement, Kubernetes utilisait Docker comme runtime par dÃ©faut. Cependant, Docker n'Ã©tant pas nativement conforme Ã  l'interface CRI (Container Runtime Interface), une couche de traduction nommÃ©e `dockershim` Ã©tait nÃ©cessaire. Depuis Kubernetes 1.24, ce support a Ã©tÃ© supprimÃ© au profit de runtimes plus lÃ©gers et spÃ©cialisÃ©s (CRI-O, containerd), rendant Docker moins pertinent dans une stack orchestrÃ©e moderne.

### 4.2.2) Podman : L'approche "Daemonless" et la sÃ©curitÃ© par le "Rootless"
Podman, dÃ©veloppÃ© par Red Hat, propose une rupture technologique en adoptant une architecture dÃ©centralisÃ©e. Au lieu d'un dÃ©mon central, Podman utilise un modÃ¨le de processus standard (fork/exec). Chaque conteneur est un processus enfant direct de l'outil de gestion, gÃ©rÃ© de maniÃ¨re autonome.

Cette mutation architecturale apporte des bÃ©nÃ©fices dÃ©cisifs pour notre projet :
- **Mode Rootless natif :** C'est l'atout majeur de Podman. Il permet Ã  un utilisateur sans privilÃ¨ges de crÃ©er, lancer et gÃ©rer des conteneurs. GrÃ¢ce Ã  l'utilisation des `User Namespaces` du noyau Linux, Podman effectue un mappage d'UID/GID (via `/etc/subuid` et `/etc/subgid`). Ainsi, un utilisateur `root` Ã  l'intÃ©rieur d'un conteneur Podman correspond en rÃ©alitÃ© Ã  un utilisateur standard sans droits sur l'hÃ´te. En cas de compromission du conteneur, l'attaquant reste confinÃ© dans un environnement aux privilÃ¨ges extrÃªmement restreints.
- **IntÃ©gration systÃ©mique avec Systemd :** Contrairement Ã  Docker qui tente de rÃ©inventer la gestion de services, Podman dÃ©lÃ¨gue cette responsabilitÃ© Ã  **Systemd**, le standard de l'industrie Linux. Nous pouvons gÃ©nÃ©rer des "Unit Files" systemd pour chaque conteneur, permettant de gÃ©rer leur cycle de vie (auto-restart, gestion des dÃ©pendances, journalisation via journald) avec la mÃªme rigueur que les services natifs de l'OS. Cela assure une persistance robuste aprÃ¨s redÃ©marrage sans dÃ©pendre d'un service tiers.
- **Convergence native avec Kubernetes :** Podman a Ã©tÃ© conÃ§u avec Kubernetes comme horizon. Il introduit nativement le concept de **Pod** (groupe de conteneurs partageant un espace rÃ©seau et des volumes), permettant de tester localement des topologies complexes identiques Ã  celles du cluster cible. De plus, Podman peut gÃ©nÃ©rer ou lire des manifestes YAML Kubernetes. Cette capacitÃ© permet de "shifter" la complexitÃ© de l'orchestration au plus tÃ´t dans le cycle de dÃ©veloppement : un dÃ©veloppeur conÃ§oit son service avec Podman et produit directement le fichier de dÃ©ploiement qui sera consommÃ© par nos pipelines CI/CD Kubernetes.
- **SouverainetÃ© et conformitÃ© OCI :** Podman respecte strictement les standards de l'Open Container Initiative (OCI) pour le runtime (`runc` ou `crun`) et le format des images. Cette conformitÃ© garantit une interopÃ©rabilitÃ© totale : toutes les images construites avec Docker sont utilisables avec Podman, et vice versa, tout en nous affranchissant des changements de licence commerciale (comme Docker Desktop) et en assurant la pÃ©rennitÃ© de notre stack Open Source.

En conclusion, l'adoption de Podman pour notre infrastructure post-hardening Ansible s'inscrit dans une dÃ©marche de **"Security by Design"**. Elle nous permet de concilier la flexibilitÃ© des conteneurs avec une isolation stricte, une gestion de services unifiÃ©e et une trajectoire de dÃ©ploiement fluide vers notre futur cluster Kubernetes.
# Partie 5 : Orchestration de conteneurs Kubernetes
## 5.1) Notions fondamentales de Kubernetes

Kubernetes est une plateforme dâ€™orchestration de conteneurs conÃ§ue pour automatiser le dÃ©ploiement, la mise Ã  lâ€™Ã©chelle et lâ€™exploitation dâ€™applications conteneurisÃ©es. LÃ  oÃ¹ un moteur de conteneurisation comme Podman ou Docker permet dâ€™exÃ©cuter un conteneur sur une machine donnÃ©e, Kubernetes introduit une **abstraction distribuÃ©e** : lâ€™application nâ€™est plus liÃ©e Ã  un hÃ´te prÃ©cis, mais devient une charge de travail orchestrÃ©e Ã  lâ€™Ã©chelle dâ€™un cluster.

Un cluster Kubernetes repose sur une architecture maÃ®tre-agents. Le **nÅ“ud maÃ®tre** (ou _control plane_) centralise les fonctions de pilotage du cluster : il maintient lâ€™Ã©tat dÃ©sirÃ© de lâ€™infrastructure, planifie les charges de travail et expose lâ€™API Kubernetes, qui constitue le point dâ€™entrÃ©e unique pour toute interaction administrative. Les **nÅ“uds workers**, quant Ã  eux, sont responsables de lâ€™exÃ©cution effective des applications. Ils hÃ©bergent les conteneurs et fournissent les ressources CPU, mÃ©moire et rÃ©seau nÃ©cessaires Ã  leur fonctionnement.

Lâ€™unitÃ© fondamentale de dÃ©ploiement dans Kubernetes est le **Pod**. Un pod reprÃ©sente une ou plusieurs instances de conteneurs partageant un mÃªme contexte dâ€™exÃ©cution (espace rÃ©seau, volumes, configuration). Dans la majoritÃ© des cas, un pod contient un seul conteneur applicatif, ce qui simplifie la gestion et le cycle de vie. Cependant, Kubernetes autorise Ã©galement des pods multi-conteneurs lorsque plusieurs processus doivent Ãªtre Ã©troitement couplÃ©s et fonctionner comme une entitÃ© logique unique (par exemple, un conteneur principal accompagnÃ© dâ€™un conteneur auxiliaire chargÃ© de la journalisation ou du proxying).

Cette approche permet Ã  Kubernetes de gÃ©rer finement la disponibilitÃ© et la rÃ©silience des applications. Les pods sont considÃ©rÃ©s comme **Ã©phÃ©mÃ¨res** : ils peuvent Ãªtre crÃ©Ã©s, dÃ©truits ou dÃ©placÃ©s automatiquement par le scheduler en fonction de lâ€™Ã©tat du cluster. Cette caractÃ©ristique impose une sÃ©paration claire entre lâ€™application elle-mÃªme et ses donnÃ©es persistantes.

La question du **stockage** est donc centrale. Kubernetes propose des mÃ©canismes de volumes persistants (PV/PVC) permettant dâ€™abstraire les ressources de stockage internes au cluster. Toutefois, dans le cadre de ce laboratoire, un choix volontairement plus simple et plus lisible a Ã©tÃ© retenu : la base de donnÃ©es est **externalisÃ©e** du cluster. Cette approche facilite la comprÃ©hension des flux, stabilise les donnÃ©es face au cycle de vie des pods et reflÃ¨te un modÃ¨le trÃ¨s courant en production, oÃ¹ les bases de donnÃ©es critiques sont souvent isolÃ©es des plateformes dâ€™orchestration applicative.

Pour permettre la communication entre les diffÃ©rents composants, Kubernetes introduit la notion de **Service**. Un service fournit une adresse rÃ©seau stable (IP virtuelle et DNS interne) pour accÃ©der Ã  un ensemble dynamique de pods. Il masque ainsi la nature Ã©phÃ©mÃ¨re des pods et assure un mÃ©canisme de rÃ©partition de charge basique entre les rÃ©plicas dâ€™une mÃªme application.

Lorsque lâ€™application doit Ãªtre exposÃ©e vers lâ€™extÃ©rieur du cluster, Kubernetes sâ€™appuie sur le concept dâ€™**Ingress**. Un Ingress dÃ©finit des rÃ¨gles de routage HTTP/HTTPS basÃ©es sur des noms de domaine et des chemins, et dÃ©lÃ¨gue leur application Ã  un contrÃ´leur Ingress (comme NGINX). Cette approche permet de centraliser lâ€™exposition rÃ©seau, dâ€™Ã©viter lâ€™ouverture de ports multiples et de se rapprocher des architectures web modernes.

Enfin, Kubernetes intÃ¨gre des mÃ©canismes natifs de **mise Ã  lâ€™Ã©chelle automatique**. Le _Horizontal Pod Autoscaler_ (HPA) ajuste dynamiquement le nombre de pods dâ€™une application en fonction de mÃ©triques, typiquement lâ€™utilisation CPU ou mÃ©moire. Ce mÃ©canisme repose sur la disponibilitÃ© dâ€™un composant dÃ©diÃ©, le **metrics-server**, chargÃ© de collecter et dâ€™exposer les mÃ©triques de consommation des nÅ“uds et des pods. Lâ€™autoscaling permet ainsi dâ€™adapter automatiquement les ressources allouÃ©es Ã  une application en fonction de la charge, sans intervention humaine.

## 5.2 Traduction de ces notions dans lâ€™architecture du laboratoire

Dans le cadre de ce projet, Kubernetes est utilisÃ© comme **socle dâ€™orchestration applicative**, dÃ©ployÃ© sur un cluster composÃ© dâ€™un nÅ“ud maÃ®tre et de plusieurs nÅ“uds workers. Cette topologie permet de dissocier clairement les fonctions de pilotage et dâ€™exÃ©cution, tout en offrant une base rÃ©aliste pour lâ€™hÃ©bergement dâ€™applications distribuÃ©es.

Lâ€™application Wiki.js est dÃ©ployÃ©e sous forme de pods rÃ©pliquÃ©s sur les nÅ“uds workers. Chaque pod exÃ©cute un conteneur Wiki.js et se connecte Ã  une base PostgreSQL hÃ©bergÃ©e sur une machine dÃ©diÃ©e, en dehors du cluster. Ce choix illustre un compromis volontaire entre simplicitÃ©, stabilitÃ© des donnÃ©es et reprÃ©sentativitÃ© des architectures professionnelles.

Lâ€™exposition rÃ©seau repose sur une chaÃ®ne de composants complÃ©mentaires. Dans un environnement on-premise, Kubernetes ne fournit pas nativement de services de type `LoadBalancer`. Pour combler ce manque, **MetalLB** est dÃ©ployÃ© afin dâ€™attribuer des adresses IP virtuelles aux services nÃ©cessitant une exposition externe. Le contrÃ´leur **Ingress NGINX** sâ€™appuie ensuite sur cette adresse pour router les requÃªtes HTTP vers les services internes du cluster, en fonction du nom de domaine configurÃ©.

La supervision minimale et lâ€™autoscaling sont rendus possibles par lâ€™installation de **metrics-server**, qui alimente Ã  la fois les commandes dâ€™observation (`kubectl top`) et le HPA. Une fois lâ€™application initialisÃ©e, Wiki.js peut ainsi Ãªtre dÃ©ployÃ©e avec plusieurs rÃ©plicas et bÃ©nÃ©ficier dâ€™une montÃ©e en charge automatique en fonction de lâ€™utilisation CPU.

## 5.3) Automatisation du dÃ©ploiement du cluster avec Ansible

Dans ce projet, Kubernetes nâ€™est jamais installÃ© manuellement. Lâ€™intÃ©gralitÃ© de la mise en place du cluster est automatisÃ©e Ã  lâ€™aide dâ€™Ansible, afin de garantir la reproductibilitÃ© du dÃ©ploiement et de limiter les erreurs humaines.

Lâ€™approche adoptÃ©e consiste Ã  dÃ©couper le dÃ©ploiement en **playbooks indÃ©pendants mais ordonnÃ©s**, chacun correspondant Ã  une brique fonctionnelle prÃ©cise du cluster. Cette organisation permet de rejouer tout ou partie du dÃ©ploiement sans impacter les composants dÃ©jÃ  en place.

## 5.4) Mise en place des services â€œplateformeâ€ du cluster

Un cluster Kubernetes minimal, bien que fonctionnel, nâ€™est pas directement exploitable dans un contexte rÃ©aliste. Plusieurs services complÃ©mentaires sont nÃ©cessaires, notamment dans un environnement on-premise.

MetalLB est utilisÃ© pour fournir des adresses IP de type `LoadBalancer`, fonctionnalitÃ© normalement assurÃ©e par les clouds publics. Le contrÃ´leur Ingress NGINX permet ensuite dâ€™exposer les applications via HTTP/HTTPS, en sâ€™appuyant sur des rÃ¨gles de routage standardisÃ©es. Enfin, `metrics-server` est indispensable pour collecter les mÃ©triques CPU et mÃ©moire, condition prÃ©alable Ã  toute politique dâ€™autoscaling.

Ces briques constituent la **couche plateforme** du cluster, sur laquelle pourront ensuite sâ€™appuyer les dÃ©ploiements applicatifs.

## 5.5) Partie pratique â€“ DÃ©ploiement complet du cluster Kubernetes

Cette section prÃ©sente le **workflow rÃ©el** utilisÃ© pour dÃ©ployer le cluster Kubernetes Ã  partir dâ€™un environnement vierge. Les commandes suivantes sont exÃ©cutÃ©es depuis le poste dâ€™administration disposant dâ€™Ansible et de lâ€™inventaire gÃ©nÃ©rÃ© par Terraform.

### **Ã‰tape 1 â€“ Initialisation du nÅ“ud maÃ®tre**
```bash
cd ~/devops/ansible ansible-playbook -i inventory.ini 1-deploy-k8s-master.yaml
```
Ce playbook prÃ©pare le nÅ“ud maÃ®tre du cluster :
- installation des dÃ©pendances Kubernetes,
- initialisation du control plane,
- configuration de lâ€™accÃ¨s administrateur via `kubectl`.

Ã€ lâ€™issue de cette Ã©tape, le cluster existe mais ne dispose encore dâ€™aucun nÅ“ud de calcul.

### **Ã‰tape 2 â€“ Ajout des nÅ“uds workers**
```bash
ansible-playbook -i inventory.ini 2-deploy-k8s-workers.yaml
```
Ce playbook automatise la jonction des nÅ“uds workers au cluster.  
Une fois terminÃ©, le cluster devient distribuÃ© et capable dâ€™exÃ©cuter des charges applicatives.

### **Ã‰tape 3 â€“ DÃ©ploiement de la base de donnÃ©es PostgreSQL (hors cluster)**
```bash
ansible-playbook -i inventory.ini 3-deploy-db-postgres.yaml
```
La base de donnÃ©es est dÃ©ployÃ©e sur une machine dÃ©diÃ©e, en dehors du cluster Kubernetes.  
Ce choix permet de garantir la persistance des donnÃ©es indÃ©pendamment du cycle de vie des pods applicatifs.

### **Ã‰tape 4 â€“ Mise en place de MetalLB**
```bash
ansible-playbook -i inventory.ini 4-deploy-metallb.yaml
```
MetalLB est installÃ© afin de permettre lâ€™utilisation de services Kubernetes de type `LoadBalancer` dans un environnement on-premise. Cette Ã©tape est indispensable pour exposer proprement des services vers le rÃ©seau local.

### **Ã‰tape 5 â€“ Installation du contrÃ´leur Ingress NGINX**
```bash
ansible-playbook -i inventory.ini 5-deploy-ingress-nginx.yaml
```
Le contrÃ´leur Ingress NGINX est dÃ©ployÃ© et exposÃ© via MetalLB.  
Il devient le point dâ€™entrÃ©e HTTP/HTTPS du cluster et permet de publier les applications Ã  lâ€™aide de rÃ¨gles Ingress standardisÃ©es.

### **Ã‰tape 6 â€“ Activation des mÃ©triques Kubernetes**
```bash
ansible-playbook -i inventory.ini 6-deploy-metrics-server.yaml
```
Le `metrics-server` est installÃ© afin de collecter les mÃ©triques CPU et mÃ©moire des pods et des nÅ“uds.  
Cette Ã©tape permet notamment lâ€™utilisation de commandes dâ€™observation (`kubectl top`) et lâ€™activation de lâ€™autoscaling horizontal.

### **Ã‰tat final du cluster**
Ã€ lâ€™issue de ces Ã©tapes, le cluster Kubernetes est pleinement opÃ©rationnel. Son Ã©tat peut Ãªtre vÃ©rifiÃ© Ã  lâ€™aide de la commande suivante :
```bash
kubectl get nodes,pods,svc,ingress,ep,hpa -A
```
Cette commande offre une vision synthÃ©tique de lâ€™ensemble des composants du cluster : nÅ“uds, workloads, services, ingress et mÃ©canismes dâ€™autoscaling.

# **Partie 6 : DÃ©ploiement applicatif avec Helm â€“ Cas de Wiki.js**

## **6.1 Enjeux du dÃ©ploiement applicatif sur Kubernetes**
Une fois la plateforme Kubernetes opÃ©rationnelle, la problÃ©matique ne se limite plus Ã  lâ€™orchestration des conteneurs, mais concerne dÃ©sormais le **dÃ©ploiement applicatif cohÃ©rent, maintenable et Ã©volutif**. Kubernetes fournit nativement les briques nÃ©cessaires Ã  lâ€™exÃ©cution dâ€™une application (pods, services, ingress), mais il ne dicte pas la maniÃ¨re dâ€™organiser un dÃ©ploiement applicatif complexe.

Dans le cas dâ€™une application telle que Wiki.js, plusieurs contraintes apparaissent rapidement : dÃ©pendance Ã  une base de donnÃ©es externe, phase dâ€™initialisation unique, exposition web sÃ©curisÃ©e, sondes de santÃ©, paramÃ¨tres de montÃ©e en charge, et gestion des mises Ã  jour. DÃ©crire manuellement lâ€™ensemble de ces Ã©lÃ©ments sous forme de manifestes Kubernetes indÃ©pendants devient vite fastidieux, peu lisible et source dâ€™erreurs.

Câ€™est dans ce contexte quâ€™intervient **Helm**, qui apporte une couche dâ€™abstraction supplÃ©mentaire dÃ©diÃ©e au packaging et au cycle de vie applicatif sur Kubernetes.

## **6.2 Helm : gestionnaire de paquets pour Kubernetes**
Helm peut Ãªtre comparÃ© Ã  un gestionnaire de paquets tel que `apt` ou `yum`, mais appliquÃ© Ã  Kubernetes. Il permet de dÃ©ployer des applications complÃ¨tes sous forme de **charts**, qui regroupent :
- les manifestes Kubernetes nÃ©cessaires (Deployments, Services, Ingress, Secrets, etc.),
- des templates dynamiques,
- et un fichier de configuration centralisÃ© (`values.yaml`) permettant dâ€™adapter le dÃ©ploiement sans modifier les templates.

Cette approche prÃ©sente plusieurs avantages majeurs :
- **Centralisation de la configuration** : lâ€™ensemble des paramÃ¨tres applicatifs est regroupÃ© dans un fichier unique.
- **Standardisation** : les charts officiels sont maintenus par les Ã©diteurs ou la communautÃ©, garantissant le respect des bonnes pratiques.
- **Gestion du cycle de vie** : Helm versionne chaque dÃ©ploiement, facilitant les mises Ã  jour, les rollbacks et les Ã©volutions progressives.
- **LisibilitÃ© et maintenabilitÃ©** : lâ€™infrastructure applicative devient plus simple Ã  comprendre et Ã  faire Ã©voluer.

Dans le cas de Wiki.js, lâ€™utilisation de Helm nâ€™est pas seulement recommandÃ©e : **elle constitue la mÃ©thode officielle prÃ©conisÃ©e par la documentation du projet** pour un dÃ©ploiement Kubernetes fiable.

## **6.3 SpÃ©cificitÃ©s de Wiki.js et nÃ©cessitÃ© dâ€™un dÃ©ploiement contrÃ´lÃ©**

Wiki.js prÃ©sente une contrainte importante lors de son dÃ©ploiement : une **phase dâ€™initialisation unique** est requise. Durant cette phase, lâ€™application :
- Ã©crit sa configuration initiale en base de donnÃ©es,
- crÃ©e les comptes par dÃ©faut,
- initialise les structures internes nÃ©cessaires Ã  son fonctionnement.

Si plusieurs instances de Wiki.js sont lancÃ©es simultanÃ©ment avant la fin de cette initialisation, des incohÃ©rences peuvent apparaÃ®tre : conflits de configuration, Ã©tats divergents entre pods, ou blocages fonctionnels. Ce comportement impose une stratÃ©gie de dÃ©ploiement en deux temps.
Le chart Helm officiel de Wiki.js permet prÃ©cisÃ©ment de gÃ©rer cette contrainte en sÃ©parant :
1. une **phase dâ€™initialisation avec un seul replica** ;
2. une **phase de mise Ã  lâ€™Ã©chelle**, une fois lâ€™application correctement configurÃ©e.

Cette distinction reflÃ¨te des pratiques industrielles courantes, oÃ¹ lâ€™on dissocie volontairement le bootstrap applicatif de la phase dâ€™exploitation.

## **6.4 DÃ©ploiement de Wiki.js : approche en deux phases**
Le dÃ©ploiement applicatif de Wiki.js dans ce projet est structurÃ© autour de deux playbooks Ansible distincts.
La premiÃ¨re phase correspond Ã  lâ€™**initialisation**. Le chart Helm est dÃ©ployÃ© avec un fichier `values.yaml` spÃ©cifique dÃ©finissant :
- un seul replica,
- la connexion Ã  la base PostgreSQL externe,
- lâ€™exposition via un Ingress,
- et des paramÃ¨tres minimaux garantissant un fonctionnement stable    

Cette phase sâ€™arrÃªte volontairement lorsque lâ€™interface web devient accessible, afin de permettre la finalisation manuelle de la configuration via lâ€™assistant graphique.

La seconde phase correspond Ã  la **mise en configuration finale**. Une fois lâ€™initialisation validÃ©e, le dÃ©ploiement est mis Ã  jour avec de nouveaux paramÃ¨tres : montÃ©e en charge, dÃ©finition des ressources, et activation de lâ€™autoscaling horizontal. Helm permet dâ€™appliquer ces changements sans redÃ©ployer lâ€™application depuis zÃ©ro.

## **6.5 Partie pratique â€“ DÃ©ploiement de Wiki.js avec Helm**
Cette section prÃ©sente le **workflow rÃ©el** utilisÃ© pour dÃ©ployer Wiki.js sur le cluster Kubernetes prÃ©cÃ©demment mis en place.

### **Ã‰tape 1 â€“ DÃ©ploiement initial de Wiki.js (phase dâ€™initialisation)**
```bash
cd ~/devops/ansible
ansible-playbook -i inventory.ini 7-deploy-wikijs-init.yaml
```

Ce playbook automatise les actions suivantes :
- installation de Helm sur le nÅ“ud maÃ®tre (si nÃ©cessaire),
- ajout du dÃ©pÃ´t officiel `requarks`,
- dÃ©ploiement du chart Wiki.js avec un fichier `values.yaml` configurÃ© pour un seul replica,
- crÃ©ation du namespace dÃ©diÃ©,    
- exposition de lâ€™application via un Ingress.

Ã€ lâ€™issue de cette Ã©tape, lâ€™interface web de Wiki.js est accessible via lâ€™URL dÃ©finie :
```
http://wikijs.lab
```

### **Ã‰tape 2 â€“ Initialisation de lâ€™application via lâ€™interface web**
Lâ€™utilisateur finalise la configuration directement depuis le navigateur :
- **Adresse email administrateur** : `test@gmail.com`
- **Mot de passe** : `azerty123`
- **URL du site** : `http://wikijs.lab`

Cette Ã©tape permet de valider la connexion Ã  la base de donnÃ©es, de crÃ©er le compte administrateur et dâ€™initialiser lâ€™Ã©tat applicatif persistant.

### **Ã‰tape 3 â€“ Mise Ã  lâ€™Ã©chelle et configuration finale**
Une fois lâ€™initialisation terminÃ©e, lâ€™application peut Ãªtre mise Ã  lâ€™Ã©chelle.
```bash
ansible-playbook -i inventory.ini 8-deploy-wikijs-scale.yaml
```
Ce playbook applique la configuration finale :
- augmentation du nombre de rÃ©plicas,
- dÃ©finition de ressources CPU/mÃ©moire,
- activation dâ€™un Horizontal Pod Autoscaler (HPA) basÃ© sur lâ€™utilisation CPU.

GrÃ¢ce Ã  Helm, cette mise Ã  jour est effectuÃ©e via une opÃ©ration dâ€™upgrade, sans interruption majeure du service.

### **VÃ©rification de lâ€™Ã©tat final**
Lâ€™Ã©tat de lâ€™application et du cluster peut Ãªtre vÃ©rifiÃ© Ã  lâ€™aide des commandes suivantes :

```bash
kubectl get pods,svc,ingress,hpa -n wikijs
kubectl top pods -n wikijs
```

Ces commandes permettent de confirmer :
- la prÃ©sence de plusieurs rÃ©plicas,
- le bon fonctionnement de lâ€™Ingress,
- et lâ€™activation effective de lâ€™autoscaling.    


## **6.5 Logique de fonctionnement du cluster â€“ Du navigateur au pod applicatif**

Une fois lâ€™ensemble des composants du cluster Kubernetes dÃ©ployÃ©s et opÃ©rationnels, il est essentiel de comprendre **le chemin exact parcouru par une requÃªte utilisateur**, depuis lâ€™accÃ¨s via un navigateur web jusquâ€™au conteneur applicatif exÃ©cutant Wiki.js. Cette section dÃ©crit pas Ã  pas la chaÃ®ne de responsabilitÃ© des diffÃ©rents composants, en prÃ©cisant pour chacun **ce quâ€™il connaÃ®t, ce quâ€™il ne connaÃ®t pas, et le rÃ´le quâ€™il joue dans le traitement de la requÃªte**.

### **Ã‰tape 1 â€“ RÃ©solution du nom et accÃ¨s Ã  lâ€™IP virtuelle**
Lâ€™utilisateur accÃ¨de Ã  lâ€™application via lâ€™URL suivante :
```
http://wikijs.lab
```

Ce nom de domaine est rÃ©solu (via le fichier `/etc/hosts` ou un DNS local) vers une **adresse IP virtuelle** :
```
192.168.122.200
```

Cette adresse IP ne correspond Ã  **aucune machine physique ni virtuelle** du cluster. Elle est fournie dynamiquement par **MetalLB**, qui joue le rÃ´le de fournisseur de services de type `LoadBalancer` dans un environnement Kubernetes on-premise.

### **Ã‰tape 2 â€“ RÃ´le de MetalLB : exposition rÃ©seau dâ€™un Service**
MetalLB ne distribue **pas** des adresses IP aux pods.  
Il attribue une adresse IP **exclusivement Ã  un objet Kubernetes de type `Service`** configurÃ© en `LoadBalancer`.

Dans ce projet, MetalLB assigne lâ€™adresse `192.168.122.200` au Service suivant :
```
Service ingress-nginx-controller (type LoadBalancer)
```

**Ce que MetalLB connaÃ®t :**
- le Service Kubernetes auquel il a attribuÃ© une IP,
- la plage dâ€™adresses IP disponibles.

**Ce que MetalLB ne connaÃ®t pas :**
- les pods,
- les applications,
- les rÃ¨gles HTTP ou les noms de domaine.

MetalLB se limite strictement Ã  un rÃ´le **rÃ©seau (L2/L3)** : rendre un Service Kubernetes accessible depuis lâ€™extÃ©rieur du cluster.

### **Ã‰tape 3 â€“ Le Service LoadBalancer : distribution vers les pods NGINX**

Le Service `ingress-nginx-controller` agit comme un **point dâ€™entrÃ©e rÃ©seau** du cluster.  
Il dispose :
- dâ€™une IP virtuelle (MetalLB),
- dâ€™une liste dâ€™**endpoints**, correspondant aux pods NGINX Ingress Controller actuellement disponibles.

Dans ce laboratoire, le contrÃ´leur Ingress NGINX est dÃ©ployÃ© avec **deux rÃ©plicas**, ce qui signifie que le Service LoadBalancer est reliÃ© Ã  deux pods NGINX distincts.

**Ce que le Service connaÃ®t :**
- la liste dynamique des pods associÃ©s (endpoints),
- leurs adresses IP internes (IP de pod).

**Ce que le Service ne connaÃ®t pas :**
- le contenu HTTP,
- les rÃ¨gles de routage,
- les applications finales.

Ã€ ce stade, le Service effectue un **Ã©quilibrage de charge de niveau rÃ©seau (L4)** et transmet la requÃªte TCP Ã  lâ€™un des pods NGINX disponibles.

### **Ã‰tape 4 â€“ Le contrÃ´leur Ingress NGINX : routage HTTP**

Le pod NGINX Ingress Controller reÃ§oit maintenant la requÃªte HTTP.  
Câ€™est **le premier composant de la chaÃ®ne Ã  comprendre le protocole HTTP**.
Le contrÃ´leur Ingress :
- Ã©coute en permanence lâ€™API Kubernetes,
- observe les objets `Ingress`, `Service` et `Endpoints`,
- gÃ©nÃ¨re dynamiquement sa configuration NGINX interne.

Dans ce projet, un objet `Ingress` dÃ©finit une rÃ¨gle de routage :
- **Host** : `wikijs.lab`
- **Service cible** : `wikijs`

Lorsquâ€™une requÃªte arrive avec lâ€™en-tÃªte HTTP :
```
Host: wikijs.lab
```

le contrÃ´leur NGINX applique la rÃ¨gle correspondante.

**Ce que NGINX connaÃ®t :**
- les rÃ¨gles Ingress,
- les Services Kubernetes cibles,
- lâ€™Ã©tat des endpoints associÃ©s aux Services.

**Ce que NGINX ne connaÃ®t pas directement :**
- les pods applicatifs individuellement,
- leur charge CPU ou mÃ©moire,
- leur emplacement exact sur les nÅ“uds.

NGINX agit donc comme un **reverse proxy applicatif**, en redirigeant la requÃªte vers le Service Kubernetes appropriÃ©.

### **Ã‰tape 5 â€“ Le Service applicatif Wiki.js : rÃ©partition vers les pods**

Le Service `wikijs` est de type `ClusterIP`.  
Il fournit une **adresse rÃ©seau stable interne** pour lâ€™application Wiki.js.

Ce Service connaÃ®t :
- la liste des pods Wiki.js actuellement actifs,
- leurs adresses IP internes.

Ã€ partir de cette liste, le Service effectue un **Ã©quilibrage de charge interne** et redirige la requÃªte vers **lâ€™un des pods Wiki.js** disponibles.

Câ€™est seulement Ã  cette Ã©tape que la requÃªte atteint le conteneur applicatif exÃ©cutant Wiki.js, qui la traite et gÃ©nÃ¨re la rÃ©ponse HTTP.

### **ChaÃ®ne complÃ¨te de traitement dâ€™une requÃªte**

On peut rÃ©sumer la logique complÃ¨te de la faÃ§on suivante :

```
Navigateur
   â†“
IP virtuelle MetalLB (192.168.122.200)
   â†“
Service ingress-nginx-controller (LoadBalancer)
   â†“
Pod NGINX Ingress Controller
   â†“
Service wikijs (ClusterIP)
   â†“
Pod Wiki.js
```

Chaque composant agit **selon son pÃ©rimÃ¨tre de responsabilitÃ©**, sans connaissance globale du systÃ¨me :

- MetalLB gÃ¨re lâ€™exposition rÃ©seau,
- le Service LoadBalancer rÃ©partit le trafic rÃ©seau,
- NGINX gÃ¨re le routage HTTP,
- les Services applicatifs assurent la distribution vers les pods,
- les pods exÃ©cutent lâ€™application.

Cette sÃ©paration stricte des rÃ´les est au cÅ“ur de la robustesse et de la scalabilitÃ© de Kubernetes.
